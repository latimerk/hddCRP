{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import hddCRP.behaviorDataHandlers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_runs = 4;\n",
    "num_warmup_samples = 2000\n",
    "num_samples        = 10000\n",
    "overwrite_existing_results = False\n",
    "\n",
    "sequential_distances_only = True # if false, model setup more as a \"smoother\". If true, can simulate from the model\n",
    "\n",
    "if(sequential_distances_only):\n",
    "    results_directory = \"Results/sequentialModel/\"\n",
    "else:\n",
    "    results_directory = \"Results\"\n",
    "if(not os.path.exists(results_directory)):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "with open('data/Data_turns_all_by_session.pkl', 'rb') as data_file:\n",
    "    data = pickle.load(data_file)\n",
    "\n",
    "subjects = list(data[\"data\"].keys())\n",
    "subjects.sort()\n",
    "print(\"subjects = \" + str(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_idx in range(num_runs):\n",
    "    for subject_idx, subject in enumerate(subjects):\n",
    "        filename = \"{results_directory}/Subject_{subject_id}_run_{run_idx}.pkl\".format(results_directory=results_directory, subject_id=subject, run_idx=run_idx)\n",
    "        if(not os.path.isfile(filename) or overwrite_existing_results):\n",
    "            # for each run, should do some randomization of initial parameters (with known seeds so we can repeat everything)\n",
    "\n",
    "            seed = subject_idx * 1000 + run_idx;\n",
    "            rng = np.random.Generator(np.random.MT19937(seed))\n",
    "\n",
    "            sequences = data[\"data\"][subject][\"data\"]; # turns in each session\n",
    "            session_types = data[\"data\"][subject][\"task\"] # which maze\n",
    "\n",
    "            model = hddCRP.behaviorDataHandlers.create_hddCRP(sequences, session_types, rng = rng, sequential_distances_only=sequential_distances_only)\n",
    "\n",
    "            tau_names = [str(xx) for xx in model.weight_param_labels]\n",
    "            alphas_names = [\"alpha_concentration_no_context\", \"alpha_concentration_one_back_context\", \"alpha_concentration_two_back_context\"]\n",
    "            model, samples, step_size_settings = hddCRP.behaviorDataHandlers.sample_model_for_maze_data(model, num_samples=num_samples, num_warmup_samples=num_warmup_samples)\n",
    "            \n",
    "            MCMC_info = {\"step_size_settings\" : step_size_settings.to_dict(),\n",
    "                        \"num_warmup_samples\" : num_warmup_samples,\n",
    "                        \"num_samples\" : num_samples,\n",
    "                        \"seed\" : seed, \n",
    "                        \"sequential_distances_only\" : sequential_distances_only}\n",
    "            samples[\"tau_parameter_names\"] = tau_names\n",
    "            samples[\"alphas_names\"] = alphas_names\n",
    "            \n",
    "            # save results to filename\n",
    "            with open(filename, \"wb\") as results_file:\n",
    "                results_data = {\"MCMC_info\" : MCMC_info,\n",
    "                                \"samples\" : samples}\n",
    "                pickle.dump(results_data, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for loading results and computing estimates with error bars for a single subject\n",
    "subject = 'A1'\n",
    "run_idx = 0;\n",
    "\n",
    "filename = \"{results_directory}/Subject_{subject_id}_run_{run_idx}.pkl\".format(results_directory=results_directory, subject_id=subject, run_idx=run_idx)\n",
    "with open(filename, \"rb\") as file:\n",
    "    results = pickle.load(file)\n",
    "\n",
    "    ss = range(results[\"MCMC_info\"][\"num_warmup_samples\"], results[\"MCMC_info\"][\"num_warmup_samples\"]+results[\"MCMC_info\"][\"num_warmup_samples\"])\n",
    "    taus = np.exp(results[\"samples\"].log_taus[ss,:])\n",
    "    alphas = results[\"samples\"].alphas[ss,:]\n",
    "\n",
    "    ci_range = [2.5, 97.5]\n",
    "\n",
    "    mean_taus = np.mean(taus, axis=0)\n",
    "    mean_alphas = np.mean(alphas, axis=0)\n",
    "    std_taus = np.std(taus, axis=0)\n",
    "    std_alphas = np.std(alphas, axis=0)\n",
    "    ci95_taus = np.percentile(taus, ci_range, axis=0)\n",
    "    ci95_alphas = np.percentile(alphas, ci_range, axis=0)\n",
    "\n",
    "    accepted = results[\"samples\"][\"accepted\"][ss]\n",
    "    print(\"Fraction of accepted MH samples: \" + str(np.mean(accepted)))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(taus)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(alphas)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaiYuLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
