{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import hddCRP.behaviorDataHandlers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects = ['A1']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "context_length = 2;\n",
    "num_runs = 1;\n",
    "runs = range(num_runs);\n",
    "num_warmup_samples = 5000\n",
    "num_samples        = 5000\n",
    "overwrite_existing_results = True\n",
    "\n",
    "simple_model = False\n",
    "single_concentration = False\n",
    "sequential_distances_only = True # if false, model setup more as a \"smoother\". If true, can simulate from the model\n",
    "\n",
    "if(sequential_distances_only):\n",
    "    results_directory = \"Results/sequentialModel/\"\n",
    "else:\n",
    "    results_directory = \"Results/\"\n",
    "if(simple_model):\n",
    "    results_directory += \"simple/\"\n",
    "elif(single_concentration):\n",
    "    results_directory += \"singleAlpha/\"\n",
    "\n",
    "if(not os.path.exists(results_directory)):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "data_filename = 'data/Data_turns_all_by_session.pkl';\n",
    "with open(data_filename, 'rb') as data_file:\n",
    "    data = pickle.load(data_file)\n",
    "\n",
    "subjects = list(data[\"data\"].keys())\n",
    "subjects = [\"A1\"]\n",
    "subjects.sort()\n",
    "print(\"subjects = \" + str(subjects))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 / 10000\n",
      "Sample 100 / 10000\n",
      "Sample 200 / 10000\n",
      "Sample 300 / 10000\n",
      "Sample 400 / 10000\n",
      "Sample 500 / 10000\n",
      "Sample 600 / 10000\n",
      "Sample 700 / 10000\n",
      "Sample 800 / 10000\n",
      "Sample 900 / 10000\n",
      "Sample 1000 / 10000\n",
      "Sample 1100 / 10000\n",
      "Sample 1200 / 10000\n",
      "Sample 1300 / 10000\n",
      "Sample 1400 / 10000\n",
      "Sample 1500 / 10000\n",
      "Sample 1600 / 10000\n",
      "Sample 1700 / 10000\n",
      "Sample 1800 / 10000\n",
      "Sample 1900 / 10000\n",
      "Sample 2000 / 10000\n",
      "Sample 2100 / 10000\n",
      "Sample 2200 / 10000\n",
      "Sample 2300 / 10000\n",
      "Sample 2400 / 10000\n",
      "Sample 2500 / 10000\n",
      "Sample 2600 / 10000\n",
      "Sample 2700 / 10000\n",
      "Sample 2800 / 10000\n",
      "Sample 2900 / 10000\n",
      "Sample 3000 / 10000\n",
      "Sample 3100 / 10000\n",
      "Sample 3200 / 10000\n",
      "Sample 3300 / 10000\n",
      "Sample 3400 / 10000\n",
      "Sample 3500 / 10000\n",
      "Sample 3600 / 10000\n",
      "Sample 3700 / 10000\n",
      "Sample 3800 / 10000\n",
      "Sample 3900 / 10000\n",
      "Sample 4000 / 10000\n",
      "Sample 4100 / 10000\n",
      "Sample 4200 / 10000\n",
      "Sample 4300 / 10000\n",
      "Sample 4400 / 10000\n",
      "Sample 4500 / 10000\n",
      "Sample 4600 / 10000\n",
      "Sample 4700 / 10000\n",
      "Sample 4800 / 10000\n",
      "Sample 4900 / 10000\n",
      "Sample 5000 / 10000\n",
      "Sample 5100 / 10000\n",
      "Sample 5200 / 10000\n",
      "Sample 5300 / 10000\n",
      "Sample 5400 / 10000\n",
      "Sample 5500 / 10000\n",
      "Sample 5600 / 10000\n",
      "Sample 5700 / 10000\n",
      "Sample 5800 / 10000\n",
      "Sample 5900 / 10000\n",
      "Sample 6000 / 10000\n",
      "Sample 6100 / 10000\n",
      "Sample 6200 / 10000\n",
      "Sample 6300 / 10000\n",
      "Sample 6400 / 10000\n",
      "Sample 6500 / 10000\n",
      "Sample 6600 / 10000\n",
      "Sample 6700 / 10000\n",
      "Sample 6800 / 10000\n",
      "Sample 6900 / 10000\n",
      "Sample 7000 / 10000\n",
      "Sample 7100 / 10000\n",
      "Sample 7200 / 10000\n",
      "Sample 7300 / 10000\n",
      "Sample 7400 / 10000\n",
      "Sample 7500 / 10000\n",
      "Sample 7600 / 10000\n",
      "Sample 7700 / 10000\n",
      "Sample 7800 / 10000\n",
      "Sample 7900 / 10000\n",
      "Sample 8000 / 10000\n",
      "Sample 8100 / 10000\n",
      "Sample 8200 / 10000\n",
      "Sample 8300 / 10000\n",
      "Sample 8400 / 10000\n",
      "Sample 8500 / 10000\n",
      "Sample 8600 / 10000\n",
      "Sample 8700 / 10000\n",
      "Sample 8800 / 10000\n",
      "Sample 8900 / 10000\n",
      "Sample 9000 / 10000\n",
      "Sample 9100 / 10000\n",
      "Sample 9200 / 10000\n",
      "Sample 9300 / 10000\n",
      "Sample 9400 / 10000\n",
      "Sample 9500 / 10000\n",
      "Sample 9600 / 10000\n",
      "Sample 9700 / 10000\n",
      "Sample 9800 / 10000\n",
      "Sample 9900 / 10000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for run_idx in runs:\n",
    "    for subject_idx, subject in enumerate(subjects):\n",
    "        filename = \"{results_directory}/Subject_{subject_id}_context_{context_length}_run_{run_idx}.pkl\".format(results_directory=results_directory, subject_id=subject, run_idx=run_idx, context_length=context_length)\n",
    "        if(not os.path.isfile(filename) or overwrite_existing_results):\n",
    "            # for each run, should do some randomization of initial parameters (with known seeds so we can repeat everything)\n",
    "\n",
    "            seed = subject_idx * 1000 + run_idx;\n",
    "            rng = np.random.Generator(np.random.MT19937(seed))\n",
    "\n",
    "            sequences = data[\"data\"][subject][\"data\"]; # turns in each session\n",
    "            session_types = data[\"data\"][subject][\"task\"] # which maze\n",
    "\n",
    "            ii = session_types.index(\"C\")\n",
    "            sequences = [sequences[ii]]\n",
    "            session_types = [session_types[ii]]\n",
    "\n",
    "\n",
    "            model = hddCRP.behaviorDataHandlers.create_hddCRP(sequences, session_types, rng = rng, \n",
    "                        sequential_distances_only=sequential_distances_only, depth=(context_length+1), include_timescales=(not simple_model))\n",
    "\n",
    "            tau_names = [str(xx) for xx in model.weight_param_labels]\n",
    "            alphas_names = [\"alpha_concentration_no_context\", \"alpha_concentration_one_back_context\", \"alpha_concentration_two_back_context\"]\n",
    "            alphas_names = alphas_names[:(context_length+1)]\n",
    "            model, samples, step_size_settings = hddCRP.behaviorDataHandlers.sample_model_for_maze_data(model, num_samples=num_samples, num_warmup_samples=num_warmup_samples, \n",
    "                print_every=100, single_concentration_parameter=(single_concentration or simple_model))\n",
    "            \n",
    "            MCMC_info = {\"step_size_settings\" : step_size_settings.to_dict(),\n",
    "                        \"num_warmup_samples\" : num_warmup_samples,\n",
    "                        \"num_samples\" : num_samples,\n",
    "                        \"seed\" : seed, \n",
    "                        \"sequential_distances_only\" : sequential_distances_only}\n",
    "            samples[\"tau_parameter_names\"] = tau_names\n",
    "            samples[\"alphas_names\"] = alphas_names\n",
    "            samples[\"stats\"] = {\"contexts\" : model._groupings, \"observations\" : model._Y}\n",
    "            \n",
    "            # save results to filename\n",
    "            with open(filename, \"wb\") as results_file:\n",
    "                results_data = {\"MCMC_info\" : MCMC_info,\n",
    "                                \"samples\" : samples}\n",
    "                pickle.dump(results_data, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for loading results and computing estimates with error bars for a single subject\n",
    "subject = 'A1'\n",
    "\n",
    "\n",
    "taus = np.zeros((10000,2,4))\n",
    "alphas = np.zeros((10000,3,4))\n",
    "\n",
    "for run_idx in range(4):\n",
    "    filename = \"{results_directory}/Subject_{subject_id}_run_{run_idx}.pkl\".format(results_directory=results_directory, subject_id=subject, run_idx=run_idx)\n",
    "    with open(filename, \"rb\") as file:\n",
    "        results = pickle.load(file)\n",
    "\n",
    "        ss = range(results[\"MCMC_info\"][\"num_warmup_samples\"], results[\"MCMC_info\"][\"num_warmup_samples\"]+results[\"MCMC_info\"][\"num_samples\"])\n",
    "        taus[:,:,run_idx] = np.exp(results[\"samples\"][\"log_taus\"][ss,:]).squeeze()\n",
    "        alphas[:,:,run_idx] = results[\"samples\"][\"alphas\"][ss,:]\n",
    "\n",
    "        # ci_range = [2.5, 97.5]\n",
    "\n",
    "        # mean_taus = np.mean(taus, axis=0)\n",
    "        # mean_alphas = np.mean(alphas, axis=0)\n",
    "        # std_taus = np.std(taus, axis=0)\n",
    "        # std_alphas = np.std(alphas, axis=0)\n",
    "        # ci95_taus = np.percentile(taus, ci_range, axis=0)\n",
    "        # ci95_alphas = np.percentile(alphas, ci_range, axis=0)\n",
    "\n",
    "        # accepted = results[\"samples\"][\"accepted\"][ss]\n",
    "        # print(\"Fraction of accepted MH samples: \" + str(np.mean(accepted)))\n",
    "\n",
    "    # plt.subplot(1,2,1)\n",
    "    # plt.plot(taus)\n",
    "\n",
    "    # plt.subplot(1,2,2)\n",
    "    # plt.plot(alphas)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "print(model._groupings[:5,:])\n",
    "# print(model._Y)\n",
    "\n",
    "prefixes = [str(xx) + '-' for xx in np.unique(model._Y)]\n",
    "combinations = list(product(prefixes, prefixes))\n",
    "\n",
    "level_0_grps = ['' for xx in combinations]\n",
    "level_1_grps = [''.join(xx[-1:]) for xx in combinations]\n",
    "level_2_grps = [''.join(xx[-2:]) for xx in combinations]\n",
    "\n",
    "print(level_0_grps)\n",
    "print(level_1_grps)\n",
    "print(level_2_grps)\n",
    "\n",
    "\n",
    "g_ns_level_0 = [int(model._groupings_compact[model._groupings[:,0] == xx,0][0]) if np.any(np.isin(xx,model._groupings[:,0])) else model.num_groups[0] for xx in level_0_grps]\n",
    "g_ns_level_1 = [int(model._groupings_compact[model._groupings[:,1] == xx,1][0]) if np.any(np.isin(xx,model._groupings[:,1])) else model.num_groups[1] for xx in level_1_grps]\n",
    "g_ns_level_2 = [int(model._groupings_compact[model._groupings[:,2] == xx,2][0]) if np.any(np.isin(xx,model._groupings[:,2])) else model.num_groups[2] for xx in level_2_grps]\n",
    "\n",
    "gnums = [g_ns_level_0, g_ns_level_1, g_ns_level_2]\n",
    "print(g_ns_level_0)\n",
    "print(g_ns_level_1)\n",
    "print(g_ns_level_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hddCRP.modelFitting import complete_exponential_distance_function_for_maze_task, hddCRPModel\n",
    "\n",
    "\n",
    "obs_idx = model.N-1\n",
    "n_obs = np.size(obs_idx)\n",
    "\n",
    "D_new = np.array(model._D[obs_idx,:,:].reshape((n_obs,model.N,1)))\n",
    "inds_new = model._weight_function_setup[\"inds\"][obs_idx,:].reshape((n_obs,model.N))\n",
    "D_new[inds_new == 0] += 1\n",
    "\n",
    "weights = complete_exponential_distance_function_for_maze_task(D_new, model.weight_params, inds_new, model._weight_function_setup[\"timescale_inds\"],model._weight_function_setup[\"constant_scale_inds\"])\n",
    "#D_new.shape\n",
    "# inds_new\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "context_length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaiYuLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
