{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import hddCRP.behaviorDataHandlers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects = ['A1']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "context_length = 2;\n",
    "num_runs = 1;\n",
    "runs = range(num_runs);\n",
    "num_warmup_samples = 2000\n",
    "num_samples        = 2000\n",
    "overwrite_existing_results = True\n",
    "\n",
    "sequential_distances_only = True # if false, model setup more as a \"smoother\". If true, can simulate from the model\n",
    "\n",
    "if(sequential_distances_only):\n",
    "    results_directory = \"Results/sequentialModel/\"\n",
    "else:\n",
    "    results_directory = \"Results\"\n",
    "if(not os.path.exists(results_directory)):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "data_filename = 'data/Data_turns_all_by_session.pkl';\n",
    "with open(data_filename, 'rb') as data_file:\n",
    "    data = pickle.load(data_file)\n",
    "\n",
    "subjects = list(data[\"data\"].keys())\n",
    "subjects = [\"A1\"]\n",
    "subjects.sort()\n",
    "print(\"subjects = \" + str(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for run_idx in runs:\n",
    "    for subject_idx, subject in enumerate(subjects):\n",
    "        filename = \"{results_directory}/Subject_{subject_id}_context_{context_length}_run_{run_idx}.pkl\".format(results_directory=results_directory, subject_id=subject, run_idx=run_idx, context_length=context_length)\n",
    "        if(not os.path.isfile(filename) or overwrite_existing_results):\n",
    "            # for each run, should do some randomization of initial parameters (with known seeds so we can repeat everything)\n",
    "\n",
    "            seed = subject_idx * 1000 + run_idx;\n",
    "            rng = np.random.Generator(np.random.MT19937(seed))\n",
    "\n",
    "            sequences = data[\"data\"][subject][\"data\"]; # turns in each session\n",
    "            session_types = data[\"data\"][subject][\"task\"] # which maze\n",
    "\n",
    "            ii = session_types.index(\"C\")\n",
    "            sequences = [sequences[ii]]\n",
    "            session_types = [session_types[ii]]\n",
    "\n",
    "\n",
    "            model = hddCRP.behaviorDataHandlers.create_hddCRP(sequences, session_types, rng = rng, sequential_distances_only=sequential_distances_only, depth=(context_length+1))\n",
    "            tau_names = [str(xx) for xx in model.weight_param_labels]\n",
    "            alphas_names = [\"alpha_concentration_no_context\", \"alpha_concentration_one_back_context\", \"alpha_concentration_two_back_context\"]\n",
    "            alphas_names = alphas_names[:(context_length+1)]\n",
    "            model, samples, step_size_settings = hddCRP.behaviorDataHandlers.sample_model_for_maze_data(model, num_samples=num_samples, num_warmup_samples=num_warmup_samples, print_every=100)\n",
    "            \n",
    "            MCMC_info = {\"step_size_settings\" : step_size_settings.to_dict(),\n",
    "                        \"num_warmup_samples\" : num_warmup_samples,\n",
    "                        \"num_samples\" : num_samples,\n",
    "                        \"seed\" : seed, \n",
    "                        \"sequential_distances_only\" : sequential_distances_only}\n",
    "            samples[\"tau_parameter_names\"] = tau_names\n",
    "            samples[\"alphas_names\"] = alphas_names\n",
    "            \n",
    "            # save results to filename\n",
    "            with open(filename, \"wb\") as results_file:\n",
    "                results_data = {\"MCMC_info\" : MCMC_info,\n",
    "                                \"samples\" : samples}\n",
    "                pickle.dump(results_data, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for loading results and computing estimates with error bars for a single subject\n",
    "subject = 'A1'\n",
    "\n",
    "\n",
    "taus = np.zeros((10000,2,4))\n",
    "alphas = np.zeros((10000,3,4))\n",
    "\n",
    "for run_idx in range(4):\n",
    "    filename = \"{results_directory}/Subject_{subject_id}_run_{run_idx}.pkl\".format(results_directory=results_directory, subject_id=subject, run_idx=run_idx)\n",
    "    with open(filename, \"rb\") as file:\n",
    "        results = pickle.load(file)\n",
    "\n",
    "        ss = range(results[\"MCMC_info\"][\"num_warmup_samples\"], results[\"MCMC_info\"][\"num_warmup_samples\"]+results[\"MCMC_info\"][\"num_samples\"])\n",
    "        taus[:,:,run_idx] = np.exp(results[\"samples\"][\"log_taus\"][ss,:]).squeeze()\n",
    "        alphas[:,:,run_idx] = results[\"samples\"][\"alphas\"][ss,:]\n",
    "\n",
    "        # ci_range = [2.5, 97.5]\n",
    "\n",
    "        # mean_taus = np.mean(taus, axis=0)\n",
    "        # mean_alphas = np.mean(alphas, axis=0)\n",
    "        # std_taus = np.std(taus, axis=0)\n",
    "        # std_alphas = np.std(alphas, axis=0)\n",
    "        # ci95_taus = np.percentile(taus, ci_range, axis=0)\n",
    "        # ci95_alphas = np.percentile(alphas, ci_range, axis=0)\n",
    "\n",
    "        # accepted = results[\"samples\"][\"accepted\"][ss]\n",
    "        # print(\"Fraction of accepted MH samples: \" + str(np.mean(accepted)))\n",
    "\n",
    "    # plt.subplot(1,2,1)\n",
    "    # plt.plot(taus)\n",
    "\n",
    "    # plt.subplot(1,2,2)\n",
    "    # plt.plot(alphas)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "print(model._groupings[:5,:])\n",
    "# print(model._Y)\n",
    "\n",
    "prefixes = [str(xx) + '-' for xx in np.unique(model._Y)]\n",
    "combinations = list(product(prefixes, prefixes))\n",
    "\n",
    "level_0_grps = ['' for xx in combinations]\n",
    "level_1_grps = [''.join(xx[-1:]) for xx in combinations]\n",
    "level_2_grps = [''.join(xx[-2:]) for xx in combinations]\n",
    "\n",
    "print(level_0_grps)\n",
    "print(level_1_grps)\n",
    "print(level_2_grps)\n",
    "\n",
    "\n",
    "g_ns_level_0 = [int(model._groupings_compact[model._groupings[:,0] == xx,0][0]) if np.any(np.isin(xx,model._groupings[:,0])) else model.num_groups[0] for xx in level_0_grps]\n",
    "g_ns_level_1 = [int(model._groupings_compact[model._groupings[:,1] == xx,1][0]) if np.any(np.isin(xx,model._groupings[:,1])) else model.num_groups[1] for xx in level_1_grps]\n",
    "g_ns_level_2 = [int(model._groupings_compact[model._groupings[:,2] == xx,2][0]) if np.any(np.isin(xx,model._groupings[:,2])) else model.num_groups[2] for xx in level_2_grps]\n",
    "\n",
    "gnums = [g_ns_level_0, g_ns_level_1, g_ns_level_2]\n",
    "print(g_ns_level_0)\n",
    "print(g_ns_level_1)\n",
    "print(g_ns_level_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hddCRP.modelFitting import complete_exponential_distance_function_for_maze_task, hddCRPModel\n",
    "\n",
    "\n",
    "obs_idx = model.N-1\n",
    "n_obs = np.size(obs_idx)\n",
    "\n",
    "D_new = np.array(model._D[obs_idx,:,:].reshape((n_obs,model.N,1)))\n",
    "inds_new = model._weight_function_setup[\"inds\"][obs_idx,:].reshape((n_obs,model.N))\n",
    "D_new[inds_new == 0] += 1\n",
    "\n",
    "weights = complete_exponential_distance_function_for_maze_task(D_new, model.weight_params, inds_new, model._weight_function_setup[\"timescale_inds\"],model._weight_function_setup[\"constant_scale_inds\"])\n",
    "#D_new.shape\n",
    "# inds_new\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaiYuLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
