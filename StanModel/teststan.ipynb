{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import numpy as np\n",
    "import stan\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ddcrp_simplified1 = \"\"\"\n",
    "data {\n",
    "    int N; // Number of data points\n",
    "    int M; // number of possible observations\n",
    "    array[N] int Y;\n",
    "    matrix[N,N] is_same_context_1;\n",
    "    matrix[N,N] is_same_1_back;\n",
    "\n",
    "    real prior_alpha_shape;\n",
    "    real prior_alpha_scale;\n",
    "\n",
    "    real prior_timeconstant_within_session_shape;\n",
    "    real prior_timeconstant_within_session_scale;\n",
    "\n",
    "    real prior_repeat_bias_1_back_shape;\n",
    "    real prior_repeat_bias_1_back_scale;\n",
    "\n",
    "    real prior_context_similarity_depth_1_alpha;\n",
    "    real prior_context_similarity_depth_1_beta;\n",
    "}\n",
    "transformed data {\n",
    "    // variables to turn main computation in matrix operations\n",
    "    matrix[N,N] is_same_observation;\n",
    "    matrix[N,N] is_prev_observation;\n",
    "    matrix[N,N] is_different_context_1;\n",
    "    matrix[N,N] deltas;\n",
    "    for (aa in 1:N) {\n",
    "        for (bb in 1:N) {\n",
    "            if(bb < aa) {\n",
    "                deltas[aa,bb] = aa-bb;\n",
    "                is_prev_observation[aa,bb] = 1;\n",
    "            }\n",
    "            else {\n",
    "                deltas[aa,bb] = 1;\n",
    "                is_prev_observation[aa,bb] = 0;\n",
    "            }\n",
    "            if(bb < aa && Y[aa] == Y[bb]) {\n",
    "                is_same_observation[aa,bb] = 1;\n",
    "            }\n",
    "            else {\n",
    "                is_same_observation[aa,bb] = 0;\n",
    "            }\n",
    "            \n",
    "            if(bb < aa && is_same_context_1[aa,bb] <= 0) {\n",
    "                is_different_context_1[aa,bb] = 1;\n",
    "            }\n",
    "            else {\n",
    "                is_different_context_1[aa,bb] = 0;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    vector[N] Y_is_same_as_one_back = rep_vector(0, N);\n",
    "    for (aa in 2:N) {\n",
    "        if(Y[aa] == Y[aa-1]) {\n",
    "            Y_is_same_as_one_back[aa] = 1;\n",
    "        }\n",
    "    }\n",
    "    // vector[N] log_BaseMeasure = rep_vector(-log(M),N) ;\n",
    "    \n",
    "    vector[N] vs = rep_vector(1.0,N) ;\n",
    "    array[N] int vi ;\n",
    "    for (aa in 1:N) {\n",
    "        vi[aa] = 1;\n",
    "    }\n",
    "\n",
    "    // prior parameter transformations for computations\n",
    "    real prior_alpha_scale_log = log(prior_alpha_scale);\n",
    "    real prior_alpha_scale_inv = 1.0/prior_alpha_scale;\n",
    "\n",
    "    real prior_timeconstant_within_session_scale_log = log(prior_timeconstant_within_session_scale);\n",
    "    real prior_timeconstant_within_session_scale_inv = 1.0/prior_timeconstant_within_session_scale;\n",
    "\n",
    "    real prior_repeat_bias_1_back_scale     = 1.0/prior_repeat_bias_1_back_shape;\n",
    "    real prior_repeat_bias_1_back_scale_inv = prior_repeat_bias_1_back_shape;\n",
    "    real prior_repeat_bias_1_back_scale_log = log(prior_repeat_bias_1_back_scale);\n",
    "}\n",
    "parameters {\n",
    "    real log_alpha_n;   \n",
    "    real log_timeconstant_within_session_n;      \n",
    "    real log_repeat_bias_1_back_n;   \n",
    "    \n",
    "    //real logit_context_similarity_depth_1;  \n",
    "    real<upper=0> log_context_similarity_depth_1;     \n",
    "}\n",
    "transformed parameters { \n",
    "    real log_alpha;   \n",
    "    real log_timeconstant_within_session;      \n",
    "    real log_repeat_bias_1_back; \n",
    "\n",
    "    log_alpha                       = log_alpha_n                       + prior_alpha_scale_log;\n",
    "    log_timeconstant_within_session = log_timeconstant_within_session_n + prior_timeconstant_within_session_scale_log;\n",
    "    log_repeat_bias_1_back          = log_repeat_bias_1_back_n          + prior_repeat_bias_1_back_scale_log;\n",
    "\n",
    "    real<lower=0> alpha;\n",
    "    real<lower=0> timeconstant_within_session;         \n",
    "    real<lower=0> repeat_bias_1_back;   \n",
    "\n",
    "    alpha                       = exp(log_alpha);\n",
    "    timeconstant_within_session = exp(log_timeconstant_within_session); \n",
    "    repeat_bias_1_back          = exp(log_repeat_bias_1_back);\n",
    "\n",
    "    real<lower=0,upper=1> context_similarity_depth_1; \n",
    "    //real<upper=0>         log_context_similarity_depth_1;\n",
    "\n",
    "    //context_similarity_depth_1     = inv_logit(logit_context_similarity_depth_1);\n",
    "    //log_context_similarity_depth_1 = log(context_similarity_depth_1);\n",
    "    context_similarity_depth_1     = exp(log_context_similarity_depth_1);\n",
    "}\n",
    "model {\n",
    "    matrix[N,N] weights_same_obs;\n",
    "    matrix[N,N] weights_all_obs;\n",
    "    vector[N] ps;\n",
    "    vector[N] aa;\n",
    "    vector[N] BaseMeasure;\n",
    "    // real BaseMeasure;\n",
    "    \n",
    "    alpha                       ~ gamma(prior_alpha_shape,                       prior_alpha_scale_inv);\n",
    "    timeconstant_within_session ~ gamma(prior_timeconstant_within_session_shape, prior_timeconstant_within_session_scale_inv);\n",
    "    repeat_bias_1_back          ~ gamma(prior_repeat_bias_1_back_shape,          prior_repeat_bias_1_back_scale_inv);\n",
    "\n",
    "    context_similarity_depth_1  ~ beta(prior_context_similarity_depth_1_alpha,   prior_context_similarity_depth_1_beta);\n",
    "    \n",
    "    BaseMeasure = ((repeat_bias_1_back-1.0) * Y_is_same_as_one_back + 1.0) / (repeat_bias_1_back + (M-1.0));\n",
    "    //BaseMeasure = 1.0/M;\n",
    "\n",
    "    weights_all_obs   = is_prev_observation .* exp(-deltas/timeconstant_within_session \n",
    "                                                   + log_context_similarity_depth_1   * is_different_context_1\n",
    "                                                   + log_repeat_bias_1_back           * is_same_1_back);\n",
    "    //weights_all_obs   = is_prev_observation .* exp(-deltas/timeconstant_within_session);\n",
    "    weights_same_obs  = is_same_observation .* weights_all_obs[:,1:N];\n",
    "\n",
    "    // probability of drawing the observed observations given their pasts\n",
    "    ps =  ((weights_same_obs * vs) + (alpha*BaseMeasure)) ./  ((weights_all_obs * vs) + (alpha));\n",
    "\n",
    "    vi ~ bernoulli(ps); // note: not generative - this is a simplified distribution to make the log likelihood computations work quickly in Stan\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.random.randint(1,3, size=(50))#np.array([1, 2, 2, 1, 1, 2, 2, 2, 1, ])\n",
    "\n",
    "N = Y.size\n",
    "M = 2;\n",
    "\n",
    "is_same_context_1 = np.zeros((N,N),dtype=int)\n",
    "is_same_1_back = np.zeros((N,N),dtype=int)\n",
    "for ii in range(1,N):\n",
    "    for jj in range(1,ii):\n",
    "        if(Y[jj-1] == Y[ii-1]):\n",
    "            is_same_context_1[ii,jj] = 1\n",
    "        if(Y[jj] == Y[ii-1]):\n",
    "            is_same_1_back[ii,jj] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data     = {\"N\" : N, \"M\" : M, \n",
    "            \"Y\" : Y,\n",
    "            \"is_same_context_1\" : is_same_context_1,\n",
    "            \"is_same_1_back\"    : is_same_1_back,\n",
    "            \"prior_alpha_shape\" : 2.0,\n",
    "            \"prior_alpha_scale\" : 5.0,\n",
    "            \"prior_timeconstant_within_session_shape\" : 2.0,\n",
    "            \"prior_timeconstant_within_session_scale\" : 25.0,\n",
    "            \"prior_repeat_bias_1_back_shape\" : 20.0,\n",
    "            \"prior_repeat_bias_1_back_scale\" : 1/20.0,\n",
    "            \"prior_context_similarity_depth_1_alpha\" : 1.0,\n",
    "            \"prior_context_similarity_depth_1_beta\"  : 1.0}\n",
    "posterior = stan.build(model_ddcrp_simplified1, data=data, random_seed=1)\n",
    "fit       = posterior.sample(num_chains=4, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fit[\"alpha\"].flatten())\n",
    "az.summary(fit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaiYuLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
