{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import hddCRP.dataLoader as dl\n",
    "import hddCRP.newContextModel2 as crp\n",
    "import hddCRP.newContextModel3 as crp3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dl.grp_names_all)\n",
    "\n",
    "results_directory = \"Results/populationNew2/\"\n",
    "if(not os.path.exists(results_directory)):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "OVERWRITE = True\n",
    "N_trials = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_trials = 50\n",
    "fit_file = f\"{results_directory}/indiv{N_trials}_fit\"\n",
    "fit_summary_file = f\"{results_directory}/indiv{N_trials}_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, subject in enumerate(dl.get_subjects()):\n",
    "    if( (\"subject\" in data_fit_metrics) and data_fit_metrics.query(\"subject == @subject\").size > 0):\n",
    "        print(f\"found subject {ii}: {subject}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"fitting subject {ii}: {subject}\")\n",
    "    rs = 2100 + ii;\n",
    "    model = crp3.create_indiv_model(subject, n_trials=N_trials)\n",
    "    # model.prior_context_a_depth_1_alpha_ = 0.5\n",
    "    # model.prior_context_a_depth_1_beta_ = 1.0\n",
    "    # model.prior_context_b_depth_1_alpha_ = model.prior_context_a_depth_1_alpha_\n",
    "    # model.prior_context_b_depth_1_beta_ = model.prior_context_a_depth_1_beta_\n",
    "\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model(num_samples=5000,num_chains=8)\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"subject\"] = subject\n",
    "    fit_df[\"group\"] = subject\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"subject\"] = subject\n",
    "    summary_df[\"group\"] = subject\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_file = f\"{results_directory}/indiv2_fit\"\n",
    "fit_summary_file = f\"{results_directory}/indiv2_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, subject in enumerate(dl.get_subjects()):\n",
    "    if( (\"subject\" in data_fit_metrics) and data_fit_metrics.query(\"subject == @subject\").size > 0):\n",
    "        print(f\"found subject {ii}: {subject}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"fitting subject {ii}: {subject}\")\n",
    "    rs = 1400 + ii;\n",
    "    model = crp.create_indiv_model(subject)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"subject\"] = subject\n",
    "    fit_df[\"group\"] = subject\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"subject\"] = subject\n",
    "    summary_df[\"group\"] = subject\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "fit_file = f\"{results_directory}/fit\"\n",
    "fit_summary_file = f\"{results_directory}/fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, group in enumerate(dl.grp_names_all):\n",
    "    if( (\"group\" in data_fit_metrics) and data_fit_metrics.query(\"group == @group\").size > 0):\n",
    "        print(f\"found group {ii}: {group}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"fitting group {ii}: {group}\")\n",
    "    rs = 1200 + ii;\n",
    "    model = crp.create_pop_model(group, n_trials=N_trials)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"group\"] = group\n",
    "    fit_df[\"subject\"] = group\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"group\"] = group\n",
    "    summary_df[\"subject\"] = group\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit_file = f\"{results_directory}/last_fit\"\n",
    "fit_summary_file = f\"{results_directory}/last_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, group in enumerate(dl.grp_names_all):\n",
    "    if( (\"group\" in data_fit_metrics) and data_fit_metrics.query(\"group == @group\").size > 0):\n",
    "        print(f\"found group {ii}: {group}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"fitting group {ii}: {group}\")\n",
    "    rs = 1200 + ii;\n",
    "    model = crp.create_pop_model(group, last=True, n_trials=N_trials)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"group\"] = group\n",
    "    fit_df[\"subject\"] = group\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"group\"] = group\n",
    "    summary_df[\"subject\"] = group\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_file = f\"{results_directory}/ts_fit\"\n",
    "fit_summary_file = f\"{results_directory}/ts_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, group in enumerate(dl.grp_names_all):\n",
    "    if( (\"group\" in data_fit_metrics) and data_fit_metrics.query(\"group == @group\").size > 0):\n",
    "        print(f\"found group {ii}: {group}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"fitting group {ii}: {group}\")\n",
    "    rs = 1300 + ii;\n",
    "    model = crp.create_pop_model(group, fold_turns=True)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"group\"] = group\n",
    "    fit_df[\"subject\"] = group\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"group\"] = group\n",
    "    summary_df[\"subject\"] = group\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_file = f\"{results_directory}/indiv2_ts_fit\"\n",
    "fit_summary_file = f\"{results_directory}/indiv2_ts_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, subject in enumerate(dl.get_subjects()):\n",
    "    if( (\"subject\" in data_fit_metrics) and data_fit_metrics.query(\"subject == @subject\").size > 0):\n",
    "        print(f\"found subject {ii}: {subject}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"fitting subject {ii}: {subject}\")\n",
    "    rs = 1500 + ii;\n",
    "    model = crp.create_indiv_model(subject, fold_turns=True)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"subject\"] = subject\n",
    "    fit_df[\"group\"] = subject\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"subject\"] = subject\n",
    "    summary_df[\"group\"] = subject\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "fit_file = f\"{results_directory}/uniformbase_fit\"\n",
    "fit_summary_file = f\"{results_directory}/uniformbase_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, group in enumerate(dl.grp_names_all):\n",
    "    if( (\"group\" in data_fit_metrics) and data_fit_metrics.query(\"group == @group\").size > 0):\n",
    "        print(f\"found group {ii}: {group}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"fitting group {ii}: {group}\")\n",
    "    rs = 1200 + ii;\n",
    "    model = crp.create_pop_model(group, n_trials=N_trials)\n",
    "    model.fit_base_measure_ = False\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    alpha = (fit_df[\"alpha\"].values)\n",
    "    fit_df[\"alpha.1\"] = alpha/3\n",
    "    fit_df[\"alpha.2\"] = alpha/3\n",
    "    fit_df[\"alpha.3\"] = alpha/3\n",
    "    fit_df[\"group\"] = group\n",
    "    fit_df[\"subject\"] = group\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"group\"] = group\n",
    "    summary_df[\"subject\"] = group\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaiYuLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
