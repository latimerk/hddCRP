{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import hddCRP.dataLoader as dl\n",
    "import hddCRP.newContextModel2 as crp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diverse_TH', 'diverse_HT', 'uniform_H', 'uniform_T', 'diverse', 'uniform']\n"
     ]
    }
   ],
   "source": [
    "print(dl.grp_names_all)\n",
    "\n",
    "results_directory = \"Results/populationNew2/\"\n",
    "if(not os.path.exists(results_directory)):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "OVERWRITE = False\n",
    "N_trials = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found subject 0: A2\n",
      "found subject 1: B2\n",
      "found subject 2: C2\n",
      "found subject 3: D2\n",
      "found subject 4: E2\n",
      "found subject 5: F2\n",
      "found subject 6: G2\n",
      "found subject 7: I2\n",
      "found subject 8: J2\n",
      "found subject 9: A1\n",
      "found subject 10: B1\n",
      "found subject 11: C1\n",
      "found subject 12: D1\n",
      "found subject 13: E1\n",
      "found subject 14: F1\n",
      "found subject 15: G1\n",
      "found subject 16: H1\n",
      "found subject 17: I1\n",
      "found subject 18: J1\n"
     ]
    }
   ],
   "source": [
    "fit_file = f\"{results_directory}/indiv2_fit\"\n",
    "fit_summary_file = f\"{results_directory}/indiv2_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, subject in enumerate(dl.get_subjects()):\n",
    "    if( (\"subject\" in data_fit_metrics) and data_fit_metrics.query(\"subject == @subject\").size > 0):\n",
    "        print(f\"found subject {ii}: {subject}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"fitting subject {ii}: {subject}\")\n",
    "    rs = 1400 + ii;\n",
    "    model = crp.create_indiv_model(subject)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"subject\"] = subject\n",
    "    fit_df[\"group\"] = subject\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"subject\"] = subject\n",
    "    summary_df[\"group\"] = subject\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting group 0: diverse_TH\n",
      "Building..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/latimerk/.cache/httpstan/4.10.1/models/cpikhn73/model_cpikhn73.cpp: In constructor ‘model_cpikhn73_namespace::model_cpikhn73::model_cpikhn73(stan::io::var_context&, unsigned int, std::ostream*)’:\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/cpikhn73/model_cpikhn73.cpp:507:19: warning: variable ‘Y_match_2’ set but not used [-Wunused-but-set-variable]\n",
      "               int Y_match_2 = std::numeric_limits<int>::min();\n",
      "                   ^~~~~~~~~\n",
      "In file included from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun.hpp:124:0,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun/multiply.hpp:7,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun/elt_multiply.hpp:9,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun.hpp:55,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev.hpp:10,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math.hpp:19,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/model/model_header.hpp:4,\n",
      "                 from /home/latimerk/.cache/httpstan/4.10.1/models/cpikhn73/model_cpikhn73.cpp:2:\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp: In instantiation of ‘TupleT stan::math::internal::grad_2F1_impl(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool calc_a1 = true; bool calc_a2 = true; bool calc_b1 = true; bool calc_z = true; T1 = double; T2 = double; T3 = double; T_z = double; ScalarT = double; TupleT = std::tuple<double, double, double, double>]’:\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:307:57:   required from ‘auto stan::math::grad_2F1(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool ReturnSameT = true; T1 = double; T2 = double; T3 = double; T_z = double; stan::require_t<std::integral_constant<bool, __v> >* <anonymous> = 0]’\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_inc_beta.hpp:37:46:   required from here\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:192:12: warning: unused variable ‘pre_mult’ [-Wunused-variable]\n",
      "       auto pre_mult = a2 * pow(1 - z, -1 - a2);\n",
      "            ^~~~~~~~\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp: In instantiation of ‘TupleT stan::math::internal::grad_2F1_impl(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool calc_a1 = true; bool calc_a2 = true; bool calc_b1 = true; bool calc_z = true; T1 = stan::math::var_value<double>; T2 = stan::math::var_value<double>; T3 = stan::math::var_value<double>; T_z = stan::math::var_value<double>; ScalarT = stan::math::var_value<double>; TupleT = std::tuple<stan::math::var_value<double, void>, stan::math::var_value<double, void>, stan::math::var_value<double, void>, stan::math::var_value<double, void> >]’:\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:307:57:   required from ‘auto stan::math::grad_2F1(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool ReturnSameT = true; T1 = stan::math::var_value<double>; T2 = stan::math::var_value<double>; T3 = stan::math::var_value<double>; T_z = stan::math::var_value<double>; stan::require_t<std::integral_constant<bool, __v> >* <anonymous> = 0]’\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun/grad_inc_beta.hpp:49:51:   required from here\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:192:12: warning: variable ‘pre_mult’ set but not used [-Wunused-but-set-variable]\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/cpikhn73/model_cpikhn73.cpp: In instantiation of ‘void model_cpikhn73_namespace::model_cpikhn73::unconstrain_array_impl(const VecVar&, const VecI&, VecVar&, std::ostream*) const [with VecVar = std::vector<double, std::allocator<double> >; VecI = std::vector<int>; stan::require_vector_t<T_y>* <anonymous> = 0; stan::require_vector_like_vt<std::is_integral, VecI>* <anonymous> = 0; std::ostream = std::basic_ostream<char>]’:\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/cpikhn73/model_cpikhn73.cpp:1022:36:   required from here\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/cpikhn73/model_cpikhn73.cpp:801:11: warning: variable ‘pos__’ set but not used [-Wunused-but-set-variable]\n",
      "       int pos__ = std::numeric_limits<int>::min();\n",
      "           ^~~~~\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/cpikhn73/model_cpikhn73.cpp: In instantiation of ‘void model_cpikhn73_namespace::model_cpikhn73::unconstrain_array_impl(const VecVar&, const VecI&, VecVar&, std::ostream*) const [with VecVar = Eigen::Matrix<double, -1, 1>; VecI = std::vector<int>; stan::require_vector_t<T_y>* <anonymous> = 0; stan::require_vector_like_vt<std::is_integral, VecI>* <anonymous> = 0; std::ostream = std::basic_ostream<char>]’:\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/cpikhn73/model_cpikhn73.cpp:1032:36:   required from here\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/cpikhn73/model_cpikhn73.cpp:801:11: warning: variable ‘pos__’ set but not used [-Wunused-but-set-variable]\n",
      "In file included from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun.hpp:124:0,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun/multiply.hpp:7,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun/elt_multiply.hpp:9,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun.hpp:55,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev.hpp:10,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math.hpp:19,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/model/model_header.hpp:4,\n",
      "                 from /home/latimerk/.cache/httpstan/4.10.1/models/cpikhn73/model_cpikhn73.cpp:2:\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp: In instantiation of ‘TupleT stan::math::internal::grad_2F1_impl_ab(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool calc_a1 = true; bool calc_a2 = true; bool calc_b1 = true; T1 = double; T2 = double; T3 = double; T_z = double; ScalarT = double; TupleT = std::tuple<double, double, double>]’:\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:205:78:   required from ‘TupleT stan::math::internal::grad_2F1_impl(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool calc_a1 = true; bool calc_a2 = true; bool calc_b1 = true; bool calc_z = true; T1 = double; T2 = double; T3 = double; T_z = double; ScalarT = double; TupleT = std::tuple<double, double, double, double>]’\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:307:57:   required from ‘auto stan::math::grad_2F1(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool ReturnSameT = true; T1 = double; T2 = double; T3 = double; T_z = double; stan::require_t<std::integral_constant<bool, __v> >* <anonymous> = 0]’\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_inc_beta.hpp:37:46:   required from here\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:68:10: warning: unused variable ‘log_precision’ [-Wunused-variable]\n",
      "   double log_precision = log(precision);\n",
      "          ^~~~~~~~~~~~~\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp: In instantiation of ‘TupleT stan::math::internal::grad_2F1_impl_ab(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool calc_a1 = true; bool calc_a2 = true; bool calc_b1 = true; T1 = stan::math::var_value<double>; T2 = stan::math::var_value<double>; T3 = stan::math::var_value<double>; T_z = stan::math::var_value<double>; ScalarT = stan::math::var_value<double>; TupleT = std::tuple<stan::math::var_value<double, void>, stan::math::var_value<double, void>, stan::math::var_value<double, void> >]’:\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:205:78:   required from ‘TupleT stan::math::internal::grad_2F1_impl(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool calc_a1 = true; bool calc_a2 = true; bool calc_b1 = true; bool calc_z = true; T1 = stan::math::var_value<double>; T2 = stan::math::var_value<double>; T3 = stan::math::var_value<double>; T_z = stan::math::var_value<double>; ScalarT = stan::math::var_value<double>; TupleT = std::tuple<stan::math::var_value<double, void>, stan::math::var_value<double, void>, stan::math::var_value<double, void>, stan::math::var_value<double, void> >]’\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:307:57:   required from ‘auto stan::math::grad_2F1(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool ReturnSameT = true; T1 = stan::math::var_value<double>; T2 = stan::math::var_value<double>; T3 = stan::math::var_value<double>; T_z = stan::math::var_value<double>; stan::require_t<std::integral_constant<bool, __v> >* <anonymous> = 0]’\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun/grad_inc_beta.hpp:49:51:   required from here\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:68:10: warning: unused variable ‘log_precision’ [-Wunused-variable]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 31.0s, done.Messages from stanc:\n",
      "Warning: The parameter timeconstant has no priors. This means either no prior\n",
      "    is provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter subject_similarity has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter context_b_depth_1 has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter context_a_depth_1 has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter alpha has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/8000)\n",
      "Sampling:   0% (2/8000)\n",
      "Sampling:   0% (3/8000)\n",
      "Sampling:   0% (4/8000)\n",
      "Sampling:   1% (103/8000)\n",
      "Sampling:   3% (202/8000)\n",
      "Sampling:   4% (301/8000)\n",
      "Sampling:   5% (400/8000)\n",
      "Sampling:   6% (500/8000)\n",
      "Sampling:   8% (600/8000)\n",
      "Sampling:   9% (700/8000)\n",
      "Sampling:  10% (800/8000)\n",
      "Sampling:  11% (900/8000)\n",
      "Sampling:  12% (1000/8000)\n",
      "Sampling:  14% (1100/8000)\n",
      "Sampling:  15% (1200/8000)\n",
      "Sampling:  16% (1300/8000)\n",
      "Sampling:  18% (1400/8000)\n",
      "Sampling:  19% (1500/8000)\n",
      "Sampling:  20% (1600/8000)\n",
      "Sampling:  21% (1700/8000)\n",
      "Sampling:  22% (1800/8000)\n",
      "Sampling:  24% (1900/8000)\n",
      "Sampling:  25% (2000/8000)\n",
      "Sampling:  26% (2100/8000)\n",
      "Sampling:  28% (2200/8000)\n",
      "Sampling:  29% (2300/8000)\n",
      "Sampling:  30% (2400/8000)\n",
      "Sampling:  31% (2500/8000)\n",
      "Sampling:  32% (2600/8000)\n",
      "Sampling:  34% (2700/8000)\n",
      "Sampling:  35% (2800/8000)\n",
      "Sampling:  36% (2900/8000)\n",
      "Sampling:  38% (3000/8000)\n",
      "Sampling:  39% (3100/8000)\n",
      "Sampling:  40% (3200/8000)\n",
      "Sampling:  41% (3300/8000)\n",
      "Sampling:  42% (3400/8000)\n",
      "Sampling:  44% (3500/8000)\n",
      "Sampling:  45% (3600/8000)\n",
      "Sampling:  46% (3701/8000)\n",
      "Sampling:  48% (3802/8000)\n",
      "Sampling:  49% (3903/8000)\n",
      "Sampling:  50% (4004/8000)\n",
      "Sampling:  51% (4103/8000)\n",
      "Sampling:  53% (4202/8000)\n",
      "Sampling:  54% (4301/8000)\n",
      "Sampling:  55% (4400/8000)\n",
      "Sampling:  56% (4500/8000)\n",
      "Sampling:  58% (4600/8000)\n",
      "Sampling:  59% (4700/8000)\n",
      "Sampling:  60% (4800/8000)\n",
      "Sampling:  61% (4900/8000)\n",
      "Sampling:  62% (5000/8000)\n",
      "Sampling:  64% (5100/8000)\n",
      "Sampling:  65% (5200/8000)\n",
      "Sampling:  66% (5300/8000)\n",
      "Sampling:  68% (5400/8000)\n",
      "Sampling:  69% (5500/8000)\n",
      "Sampling:  70% (5600/8000)\n",
      "Sampling:  71% (5700/8000)\n",
      "Sampling:  72% (5800/8000)\n",
      "Sampling:  74% (5900/8000)\n",
      "Sampling:  75% (6000/8000)\n",
      "Sampling:  76% (6100/8000)\n",
      "Sampling:  78% (6200/8000)\n",
      "Sampling:  79% (6300/8000)\n",
      "Sampling:  80% (6400/8000)\n",
      "Sampling:  81% (6500/8000)\n",
      "Sampling:  82% (6600/8000)\n",
      "Sampling:  84% (6700/8000)\n",
      "Sampling:  85% (6800/8000)\n",
      "Sampling:  86% (6900/8000)\n",
      "Sampling:  88% (7000/8000)\n",
      "Sampling:  89% (7100/8000)\n",
      "Sampling:  90% (7200/8000)\n",
      "Sampling:  91% (7300/8000)\n",
      "Sampling:  92% (7400/8000)\n",
      "Sampling:  94% (7500/8000)\n",
      "Sampling:  95% (7600/8000)\n",
      "Sampling:  96% (7700/8000)\n",
      "Sampling:  98% (7800/8000)\n",
      "Sampling:  99% (7900/8000)\n",
      "Sampling: 100% (8000/8000)\n",
      "Sampling: 100% (8000/8000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.039352 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 393.52 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: bernoulli_lpmf: Probability parameter[1] is -nan, but must be in the interval [0, 1] (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 122, column 4 to column 22)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: bernoulli_lpmf: Probability parameter[1] is -nan, but must be in the interval [0, 1] (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 122, column 4 to column 22)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.039216 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 392.16 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 0.042194 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 421.94 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: bernoulli_lpmf: Probability parameter[1] is -nan, but must be in the interval [0, 1] (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 122, column 4 to column 22)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: bernoulli_lpmf: Probability parameter[1] is -nan, but must be in the interval [0, 1] (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 122, column 4 to column 22)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.042976 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 429.76 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: bernoulli_lpmf: Probability parameter[1] is -nan, but must be in the interval [0, 1] (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 122, column 4 to column 22)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: bernoulli_lpmf: Probability parameter[1] is -nan, but must be in the interval [0, 1] (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 122, column 4 to column 22)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting group 1: diverse_HT\n",
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning: The parameter timeconstant has no priors. This means either no prior\n",
      "    is provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter subject_similarity has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter context_b_depth_1 has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter context_a_depth_1 has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter alpha has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/8000)\n",
      "Sampling:   0% (2/8000)\n",
      "Sampling:   0% (3/8000)\n",
      "Sampling:   0% (4/8000)\n",
      "Sampling:   1% (103/8000)\n",
      "Sampling:   3% (202/8000)\n",
      "Sampling:   4% (301/8000)\n",
      "Sampling:   5% (400/8000)\n",
      "Sampling:   6% (500/8000)\n",
      "Sampling:   8% (600/8000)\n",
      "Sampling:   9% (700/8000)\n",
      "Sampling:  10% (800/8000)\n",
      "Sampling:  11% (900/8000)\n",
      "Sampling:  12% (1000/8000)\n",
      "Sampling:  14% (1100/8000)\n",
      "Sampling:  15% (1200/8000)\n",
      "Sampling:  16% (1300/8000)\n",
      "Sampling:  18% (1400/8000)\n",
      "Sampling:  19% (1500/8000)\n",
      "Sampling:  20% (1600/8000)\n",
      "Sampling:  21% (1700/8000)\n",
      "Sampling:  22% (1800/8000)\n",
      "Sampling:  24% (1900/8000)\n",
      "Sampling:  25% (2000/8000)\n",
      "Sampling:  26% (2100/8000)\n",
      "Sampling:  28% (2200/8000)\n",
      "Sampling:  29% (2300/8000)\n",
      "Sampling:  30% (2400/8000)\n",
      "Sampling:  31% (2500/8000)\n",
      "Sampling:  32% (2600/8000)\n",
      "Sampling:  34% (2700/8000)\n",
      "Sampling:  35% (2800/8000)\n",
      "Sampling:  36% (2900/8000)\n",
      "Sampling:  38% (3000/8000)\n",
      "Sampling:  39% (3100/8000)\n",
      "Sampling:  40% (3200/8000)\n",
      "Sampling:  41% (3300/8000)\n",
      "Sampling:  42% (3400/8000)\n",
      "Sampling:  44% (3500/8000)\n",
      "Sampling:  45% (3600/8000)\n",
      "Sampling:  46% (3701/8000)\n",
      "Sampling:  48% (3802/8000)\n",
      "Sampling:  49% (3903/8000)\n",
      "Sampling:  50% (4002/8000)\n",
      "Sampling:  51% (4103/8000)\n",
      "Sampling:  53% (4202/8000)\n",
      "Sampling:  54% (4301/8000)\n",
      "Sampling:  55% (4401/8000)\n",
      "Sampling:  56% (4500/8000)\n",
      "Sampling:  58% (4600/8000)\n",
      "Sampling:  59% (4700/8000)\n",
      "Sampling:  60% (4800/8000)\n",
      "Sampling:  61% (4900/8000)\n",
      "Sampling:  62% (5000/8000)\n",
      "Sampling:  64% (5100/8000)\n",
      "Sampling:  65% (5200/8000)\n",
      "Sampling:  66% (5300/8000)\n",
      "Sampling:  68% (5400/8000)\n",
      "Sampling:  69% (5500/8000)\n",
      "Sampling:  70% (5600/8000)\n",
      "Sampling:  71% (5700/8000)\n",
      "Sampling:  72% (5800/8000)\n",
      "Sampling:  74% (5900/8000)\n",
      "Sampling:  75% (6000/8000)\n",
      "Sampling:  76% (6100/8000)\n",
      "Sampling:  78% (6200/8000)\n",
      "Sampling:  79% (6300/8000)\n",
      "Sampling:  80% (6400/8000)\n",
      "Sampling:  81% (6500/8000)\n",
      "Sampling:  82% (6600/8000)\n",
      "Sampling:  84% (6700/8000)\n",
      "Sampling:  85% (6800/8000)\n",
      "Sampling:  86% (6900/8000)\n",
      "Sampling:  88% (7000/8000)\n",
      "Sampling:  89% (7100/8000)\n",
      "Sampling:  90% (7200/8000)\n",
      "Sampling:  91% (7300/8000)\n",
      "Sampling:  92% (7400/8000)\n",
      "Sampling:  94% (7500/8000)\n",
      "Sampling:  95% (7600/8000)\n",
      "Sampling:  96% (7700/8000)\n",
      "Sampling:  98% (7800/8000)\n",
      "Sampling:  99% (7900/8000)\n",
      "Sampling: 100% (8000/8000)\n",
      "Sampling: 100% (8000/8000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.024496 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 244.96 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: gamma_lpdf: Random variable[3] is 0, but must be positive finite! (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 101, column 4 to column 90)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.024321 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 243.21 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 0.026691 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 266.91 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: gamma_lpdf: Random variable[2] is inf, but must be positive finite! (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 101, column 4 to column 90)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.026984 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 269.84 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: bernoulli_lpmf: Probability parameter[1] is -nan, but must be in the interval [0, 1] (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 122, column 4 to column 22)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting group 2: uniform_H\n",
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning: The parameter timeconstant has no priors. This means either no prior\n",
      "    is provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter subject_similarity has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter context_b_depth_1 has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter context_a_depth_1 has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter alpha has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/8000)\n",
      "Sampling:   0% (2/8000)\n",
      "Sampling:   0% (3/8000)\n",
      "Sampling:   0% (4/8000)\n",
      "Sampling:   1% (103/8000)\n",
      "Sampling:   3% (202/8000)\n",
      "Sampling:   4% (301/8000)\n",
      "Sampling:   5% (400/8000)\n",
      "Sampling:   6% (500/8000)\n",
      "Sampling:   8% (600/8000)\n",
      "Sampling:   9% (700/8000)\n",
      "Sampling:  10% (800/8000)\n",
      "Sampling:  11% (900/8000)\n",
      "Sampling:  12% (1000/8000)\n",
      "Sampling:  14% (1100/8000)\n",
      "Sampling:  15% (1200/8000)\n",
      "Sampling:  16% (1300/8000)\n",
      "Sampling:  18% (1400/8000)\n",
      "Sampling:  19% (1500/8000)\n",
      "Sampling:  20% (1600/8000)\n",
      "Sampling:  21% (1700/8000)\n",
      "Sampling:  22% (1800/8000)\n",
      "Sampling:  24% (1900/8000)\n",
      "Sampling:  25% (2000/8000)\n",
      "Sampling:  26% (2100/8000)\n",
      "Sampling:  28% (2200/8000)\n",
      "Sampling:  29% (2300/8000)\n",
      "Sampling:  30% (2400/8000)\n",
      "Sampling:  31% (2500/8000)\n",
      "Sampling:  32% (2600/8000)\n",
      "Sampling:  34% (2700/8000)\n",
      "Sampling:  35% (2800/8000)\n",
      "Sampling:  36% (2900/8000)\n",
      "Sampling:  38% (3000/8000)\n",
      "Sampling:  39% (3100/8000)\n",
      "Sampling:  40% (3200/8000)\n",
      "Sampling:  41% (3300/8000)\n",
      "Sampling:  42% (3400/8000)\n",
      "Sampling:  44% (3500/8000)\n",
      "Sampling:  45% (3600/8000)\n",
      "Sampling:  46% (3700/8000)\n",
      "Sampling:  46% (3701/8000)\n",
      "Sampling:  48% (3802/8000)\n",
      "Sampling:  49% (3903/8000)\n",
      "Sampling:  50% (4004/8000)\n",
      "Sampling:  51% (4103/8000)\n",
      "Sampling:  53% (4202/8000)\n",
      "Sampling:  54% (4301/8000)\n",
      "Sampling:  55% (4400/8000)\n",
      "Sampling:  56% (4500/8000)\n",
      "Sampling:  58% (4600/8000)\n",
      "Sampling:  59% (4700/8000)\n",
      "Sampling:  60% (4800/8000)\n",
      "Sampling:  61% (4900/8000)\n",
      "Sampling:  62% (5000/8000)\n",
      "Sampling:  64% (5100/8000)\n",
      "Sampling:  65% (5200/8000)\n",
      "Sampling:  66% (5300/8000)\n",
      "Sampling:  68% (5400/8000)\n",
      "Sampling:  69% (5500/8000)\n",
      "Sampling:  70% (5600/8000)\n",
      "Sampling:  71% (5700/8000)\n",
      "Sampling:  72% (5800/8000)\n",
      "Sampling:  74% (5900/8000)\n",
      "Sampling:  75% (6000/8000)\n",
      "Sampling:  76% (6100/8000)\n",
      "Sampling:  78% (6200/8000)\n",
      "Sampling:  79% (6300/8000)\n",
      "Sampling:  80% (6400/8000)\n",
      "Sampling:  81% (6500/8000)\n",
      "Sampling:  82% (6600/8000)\n",
      "Sampling:  84% (6700/8000)\n",
      "Sampling:  85% (6800/8000)\n",
      "Sampling:  86% (6900/8000)\n",
      "Sampling:  88% (7000/8000)\n",
      "Sampling:  89% (7100/8000)\n",
      "Sampling:  90% (7200/8000)\n",
      "Sampling:  91% (7300/8000)\n",
      "Sampling:  92% (7400/8000)\n",
      "Sampling:  94% (7500/8000)\n",
      "Sampling:  95% (7600/8000)\n",
      "Sampling:  96% (7700/8000)\n",
      "Sampling:  98% (7800/8000)\n",
      "Sampling:  99% (7900/8000)\n",
      "Sampling: 100% (8000/8000)\n",
      "Sampling: 100% (8000/8000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.037854 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 378.54 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: gamma_lpdf: Random variable[1] is inf, but must be positive finite! (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 101, column 4 to column 90)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.051153 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 511.53 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: bernoulli_lpmf: Probability parameter[1] is -nan, but must be in the interval [0, 1] (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 122, column 4 to column 22)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: bernoulli_lpmf: Probability parameter[1] is -nan, but must be in the interval [0, 1] (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 122, column 4 to column 22)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: bernoulli_lpmf: Probability parameter[1] is -nan, but must be in the interval [0, 1] (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 122, column 4 to column 22)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.058594 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 585.94 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: bernoulli_lpmf: Probability parameter[1] is -nan, but must be in the interval [0, 1] (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 122, column 4 to column 22)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: bernoulli_lpmf: Probability parameter[1] is -nan, but must be in the interval [0, 1] (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 122, column 4 to column 22)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n",
      "  Gradient evaluation took 0.040139 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 401.39 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: gamma_lpdf: Random variable[1] is inf, but must be positive finite! (in '/tmp/httpstan_t5mcsdtc/model_cpikhn73.stan', line 101, column 4 to column 90)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting group 3: uniform_T\n",
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning: The parameter timeconstant has no priors. This means either no prior\n",
      "    is provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter subject_similarity has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter context_b_depth_1 has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter context_a_depth_1 has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter alpha has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/8000)\n",
      "Sampling:   0% (2/8000)\n",
      "Sampling:   0% (3/8000)\n",
      "Sampling:   0% (4/8000)\n",
      "Sampling:   1% (103/8000)\n",
      "Sampling:   3% (202/8000)\n",
      "Sampling:   4% (301/8000)\n",
      "Sampling:   5% (400/8000)\n",
      "Sampling:   6% (500/8000)\n",
      "Sampling:   8% (600/8000)\n",
      "Sampling:   9% (700/8000)\n",
      "Sampling:  10% (800/8000)\n",
      "Sampling:  11% (900/8000)\n",
      "Sampling:  12% (1000/8000)\n",
      "Sampling:  14% (1100/8000)\n",
      "Sampling:  15% (1200/8000)\n",
      "Sampling:  16% (1300/8000)\n",
      "Sampling:  18% (1400/8000)\n",
      "Sampling:  19% (1500/8000)\n",
      "Sampling:  20% (1600/8000)\n",
      "Sampling:  21% (1700/8000)\n",
      "Sampling:  22% (1800/8000)\n",
      "Sampling:  24% (1900/8000)\n",
      "Sampling:  25% (2000/8000)\n",
      "Sampling:  26% (2100/8000)\n",
      "Sampling:  28% (2200/8000)\n",
      "Sampling:  29% (2300/8000)\n",
      "Sampling:  30% (2400/8000)\n",
      "Sampling:  31% (2500/8000)\n",
      "Sampling:  32% (2600/8000)\n",
      "Sampling:  34% (2700/8000)\n",
      "Sampling:  35% (2800/8000)\n",
      "Sampling:  36% (2900/8000)\n",
      "Sampling:  38% (3000/8000)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "fit_file = f\"{results_directory}/fit\"\n",
    "fit_summary_file = f\"{results_directory}/fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, group in enumerate(dl.grp_names_all):\n",
    "    if( (\"group\" in data_fit_metrics) and data_fit_metrics.query(\"group == @group\").size > 0):\n",
    "        print(f\"found group {ii}: {group}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"fitting group {ii}: {group}\")\n",
    "    rs = 1200 + ii;\n",
    "    model = crp.create_pop_model(group, n_trials=N_trials)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"group\"] = group\n",
    "    fit_df[\"subject\"] = group\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"group\"] = group\n",
    "    summary_df[\"subject\"] = group\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit_file = f\"{results_directory}/last_fit\"\n",
    "fit_summary_file = f\"{results_directory}/last_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, group in enumerate(dl.grp_names_all):\n",
    "    if( (\"group\" in data_fit_metrics) and data_fit_metrics.query(\"group == @group\").size > 0):\n",
    "        print(f\"found group {ii}: {group}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"fitting group {ii}: {group}\")\n",
    "    rs = 1200 + ii;\n",
    "    model = crp.create_pop_model(group, last=True, n_trials=N_trials)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"group\"] = group\n",
    "    fit_df[\"subject\"] = group\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"group\"] = group\n",
    "    summary_df[\"subject\"] = group\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_file = f\"{results_directory}/ts_fit\"\n",
    "fit_summary_file = f\"{results_directory}/ts_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, group in enumerate(dl.grp_names_all):\n",
    "    if( (\"group\" in data_fit_metrics) and data_fit_metrics.query(\"group == @group\").size > 0):\n",
    "        print(f\"found group {ii}: {group}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"fitting group {ii}: {group}\")\n",
    "    rs = 1300 + ii;\n",
    "    model = crp.create_pop_model(group, fold_turns=True)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"group\"] = group\n",
    "    fit_df[\"subject\"] = group\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"group\"] = group\n",
    "    summary_df[\"subject\"] = group\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_file = f\"{results_directory}/indiv2_ts_fit\"\n",
    "fit_summary_file = f\"{results_directory}/indiv2_ts_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, subject in enumerate(dl.get_subjects()):\n",
    "    if( (\"subject\" in data_fit_metrics) and data_fit_metrics.query(\"subject == @subject\").size > 0):\n",
    "        print(f\"found subject {ii}: {subject}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"fitting subject {ii}: {subject}\")\n",
    "    rs = 1500 + ii;\n",
    "    model = crp.create_indiv_model(subject, fold_turns=True)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"subject\"] = subject\n",
    "    fit_df[\"group\"] = subject\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"subject\"] = subject\n",
    "    summary_df[\"group\"] = subject\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "fit_file = f\"{results_directory}/uniformbase_fit\"\n",
    "fit_summary_file = f\"{results_directory}/uniformbase_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, group in enumerate(dl.grp_names_all):\n",
    "    if( (\"group\" in data_fit_metrics) and data_fit_metrics.query(\"group == @group\").size > 0):\n",
    "        print(f\"found group {ii}: {group}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"fitting group {ii}: {group}\")\n",
    "    rs = 1200 + ii;\n",
    "    model = crp.create_pop_model(group, n_trials=N_trials)\n",
    "    model.fit_base_measure_ = False\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    alpha = (fit_df[\"alpha\"].values)\n",
    "    fit_df[\"alpha.1\"] = alpha/3\n",
    "    fit_df[\"alpha.2\"] = alpha/3\n",
    "    fit_df[\"alpha.3\"] = alpha/3\n",
    "    fit_df[\"group\"] = group\n",
    "    fit_df[\"subject\"] = group\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"group\"] = group\n",
    "    summary_df[\"subject\"] = group\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaiYuLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
