{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from hddCRP.modelBuilder import cdCRP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from statannotations.Annotator import Annotator\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import itertools\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups = ['uniform', 'diverse']\n"
     ]
    }
   ],
   "source": [
    "overwrite_existing_results = False\n",
    "results_directory = \"Results/population/LOO/\"\n",
    "\n",
    "if(not os.path.exists(results_directory)):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "data_filename = 'data/Data_turns_all_by_session.pkl';\n",
    "with open(data_filename, 'rb') as data_file:\n",
    "    data = pickle.load(data_file)\n",
    "\n",
    "groups = [\"uniform\", \"diverse\"]\n",
    "print(\"groups = \" + str(groups))\n",
    "\n",
    "session_numbers = None#[1]; # index by 1\n",
    "number_of_trials    = 100;\n",
    "\n",
    "action_labels = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fit(stan_seed, sequences_c, session_types_c, subject_labels_c, population_labels_c, subject_label, context_depth, nback_depth):\n",
    "    model = cdCRP(sequences_c,\n",
    "                    session_labels=session_types_c,\n",
    "                    subject_labels=subject_labels_c,\n",
    "                    population_labels=population_labels_c,\n",
    "                    possible_observations=action_labels);\n",
    "    model.same_nback_depth = nback_depth\n",
    "    model.context_depth = context_depth\n",
    "\n",
    "    model.build(random_seed=stan_seed);\n",
    "    model.fit_model()\n",
    "\n",
    "    fit_df  = model.fit.to_frame()\n",
    "    summary_df = model.fit_summary()\n",
    "\n",
    "    fit_df[\"loo_subject\"]   = subject_label\n",
    "    summary_df[\"loo_subject\"] = subject_label\n",
    "\n",
    "    if(session_numbers is None):\n",
    "        summary_df[\"number_of_trials\"] = number_of_trials\n",
    "        summary_df[\"start_session_C\"]  = pd.NA\n",
    "        summary_df[\"end_session_C\"]    = pd.NA\n",
    "        fit_df[\"number_of_trials\"] = number_of_trials\n",
    "        fit_df[\"start_session_C\"]  = pd.NA\n",
    "        fit_df[\"end_session_C\"]    = pd.NA\n",
    "    else:\n",
    "        start_session = np.min(session_numbers)\n",
    "        end_session = np.max(session_numbers)\n",
    "        summary_df[\"number_of_trials\"] = pd.NA\n",
    "        summary_df[\"start_session_C\"]  = start_session\n",
    "        summary_df[\"end_session_C\"]    = end_session\n",
    "        fit_df[\"number_of_trials\"] = pd.NA\n",
    "        fit_df[\"start_session_C\"]  = start_session\n",
    "        fit_df[\"end_session_C\"]    = end_session\n",
    "    return fit_df, summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 1. 2. 0.]\n",
      "[[ 0 -1 -2 -3 -4]\n",
      " [ 1  0 -1 -2 -3]\n",
      " [ 2  1  0 -1 -2]\n",
      " [ 3  2  1  0 -1]\n",
      " [ 4  3  2  1  0]]\n",
      "[[False False False False False]\n",
      " [ True False False False False]\n",
      " [ True  True False False False]\n",
      " [ True  True  True False False]\n",
      " [ True  True  True  True False]]\n",
      "[[ True False  True False False]\n",
      " [False  True False  True False]\n",
      " [ True False  True False False]\n",
      " [False  True False  True False]\n",
      " [False False False False  True]]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [1. 1. 0. 1. 0.]]\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 1. 0. 0. 0.]\n",
      " [1. 1. 1. 0. 0.]\n",
      " [1. 1. 0. 1. 0.]]\n",
      "[False False False False False]\n"
     ]
    }
   ],
   "source": [
    "def xval_sequence(seq, fit_df, context_depth, nback_depth):\n",
    "    Y = np.array(seq,dtype=float);\n",
    "    N = Y.size\n",
    "\n",
    "    deltas = np.arange(0,N)[:,np.newaxis] - np.arange(0,N)[np.newaxis,:]\n",
    "\n",
    "    is_prev = deltas > 0;\n",
    "    is_same = (Y[:,np.newaxis] == Y[np.newaxis,:])\n",
    "    \n",
    "\n",
    "    ctx = Y.copy()\n",
    "    A = np.zeros((N,N),dtype=int)\n",
    "    cd = np.zeros((N,N,context_depth))\n",
    "    for depth in range(context_depth):\n",
    "        ctx = np.roll(ctx,1)\n",
    "        ctx[0] = np.nan\n",
    "        A = (ctx[:,np.newaxis] != ctx[np.newaxis,:]) | A\n",
    "        cd[:,:,depth] = np.tril(A,-1);\n",
    "\n",
    "\n",
    "    if(nback_depth > 0):\n",
    "        ctx = np.roll(Y.copy(), 1)\n",
    "        ctx[0] = np.nan\n",
    "        sb = Y == ctx\n",
    "    else:\n",
    "        sb = 0;\n",
    "    \n",
    "    if(fit_df is None):\n",
    "        print(Y[:5])\n",
    "        print(deltas[:5,:5])\n",
    "        print(is_prev[:5,:5])\n",
    "        print(is_same[:5,:5])\n",
    "        for depth in range(context_depth):\n",
    "            print(cd[:5,:5,depth])\n",
    "        if(nback_depth > 0):\n",
    "            print(sb[:5])\n",
    "        return\n",
    "       \n",
    "\n",
    "    M = len(action_labels)\n",
    "\n",
    "    def compute_log_p(df_row):\n",
    "        tau = df_row[\"timeconstant_within_session_C\"]\n",
    "        alpha = df_row[\"alpha\"]\n",
    "        \n",
    "\n",
    "        if(nback_depth > 0):\n",
    "            repeat_bias_1_back_0 = df_row[\"repeat_bias_1_back\"]\n",
    "            BaseMeasure = (sb * (repeat_bias_1_back_0-1.0) + 1.0) / (repeat_bias_1_back_0 + (M-1.0));\n",
    "        else:\n",
    "            BaseMeasure = 1.0/M;\n",
    "        if(context_depth > 0):\n",
    "            C = np.array([df_row[f\"context_similarity_depth_{xx}\"] for xx in range(1,context_depth+1)])\n",
    "            cm = np.sum(np.log(1.0-C[np.newaxis,np.newaxis,:]) * cd, axis=2)\n",
    "        else:\n",
    "            cm = 0;\n",
    "        X = np.exp(-deltas/tau + cm) * is_prev\n",
    "        Y = X * is_same\n",
    "\n",
    "        log_P = np.log(Y.sum(axis=1) + alpha*BaseMeasure) - np.log(X.sum(axis=1) + alpha)\n",
    "        return log_P.sum()\n",
    "\n",
    "    return fit_df.apply(compute_log_p, axis=1)\n",
    "xval_sequence([1,2,1,2,0,1,0],None,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences of 100 trials\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['uniform',\n",
       " 'uniform',\n",
       " 'uniform',\n",
       " 'uniform',\n",
       " 'uniform',\n",
       " 'uniform',\n",
       " 'uniform',\n",
       " 'uniform',\n",
       " 'uniform',\n",
       " 'uniform',\n",
       " 'diverse',\n",
       " 'diverse',\n",
       " 'diverse',\n",
       " 'diverse',\n",
       " 'diverse',\n",
       " 'diverse',\n",
       " 'diverse',\n",
       " 'diverse',\n",
       " 'diverse']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sequences = []\n",
    "session_types = []\n",
    "subject_labels = []\n",
    "population_labels = []\n",
    "for group in groups:\n",
    "    subs = data[\"group_definition\"][group];\n",
    "    subs.sort()\n",
    "    for subject_p in subs:\n",
    "        sequences_0 = data[\"data\"][subject_p][\"data\"]; # turns in each session\n",
    "        session_types_0 = data[\"data\"][subject_p][\"task\"] # which maze\n",
    "\n",
    "        \n",
    "        if(session_numbers is None):\n",
    "            ii = list(np.where(np.array(session_types_0)=='C')[0])\n",
    "            seqs_c = [sequences_0[xx] for xx in ii]\n",
    "            seqs_c = list(itertools.chain.from_iterable(seqs_c))\n",
    "            sequences += [seqs_c[:number_of_trials]]\n",
    "            session_types += ['C']\n",
    "            subject_labels += [subject_p]\n",
    "            population_labels += [group]\n",
    "        else:\n",
    "            ii = list(np.where(np.array(session_types_0)=='C')[0][np.array(session_numbers)-1])\n",
    "            sequences     += [sequences_0[xx] for xx in ii]\n",
    "            session_types += [session_types_0[xx] for xx in ii]\n",
    "            subject_labels += [subject_p] * len(ii)\n",
    "            population_labels += [group]* len(ii)\n",
    "            if(len(ii) > 1):\n",
    "                raise ValueError(\"only should do one sequence per subject\")\n",
    "if(session_numbers is None):\n",
    "    print(f\"Sequences of {number_of_trials} trials\")\n",
    "else:\n",
    "    print(f\"WARNING: Using sessions {session_numbers}\")\n",
    "\n",
    "population_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject A1 in group uniform, cd = 0, nb = 0\n",
      "fitting with ['B1', 'C1', 'D1', 'E1', 'F1', 'G1', 'H1', 'I1', 'J1'], cd = 0, nb = 0\n",
      "Building..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/latimerk/.cache/httpstan/4.10.1/models/kkoj3jfj/model_kkoj3jfj.cpp: In constructor ‘model_kkoj3jfj_namespace::model_kkoj3jfj::model_kkoj3jfj(stan::io::var_context&, unsigned int, std::ostream*)’:\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/kkoj3jfj/model_kkoj3jfj.cpp:154:11: warning: variable ‘pos__’ set but not used [-Wunused-but-set-variable]\n",
      "       int pos__ = std::numeric_limits<int>::min();\n",
      "           ^~~~~\n",
      "In file included from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun.hpp:124:0,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun/multiply.hpp:7,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun/elt_multiply.hpp:9,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun.hpp:55,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev.hpp:10,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math.hpp:19,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/model/model_header.hpp:4,\n",
      "                 from /home/latimerk/.cache/httpstan/4.10.1/models/kkoj3jfj/model_kkoj3jfj.cpp:2:\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp: In instantiation of ‘TupleT stan::math::internal::grad_2F1_impl(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool calc_a1 = true; bool calc_a2 = true; bool calc_b1 = true; bool calc_z = true; T1 = double; T2 = double; T3 = double; T_z = double; ScalarT = double; TupleT = std::tuple<double, double, double, double>]’:\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:307:57:   required from ‘auto stan::math::grad_2F1(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool ReturnSameT = true; T1 = double; T2 = double; T3 = double; T_z = double; stan::require_t<std::integral_constant<bool, __v> >* <anonymous> = 0]’\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_inc_beta.hpp:37:46:   required from here\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:192:12: warning: unused variable ‘pre_mult’ [-Wunused-variable]\n",
      "       auto pre_mult = a2 * pow(1 - z, -1 - a2);\n",
      "            ^~~~~~~~\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp: In instantiation of ‘TupleT stan::math::internal::grad_2F1_impl(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool calc_a1 = true; bool calc_a2 = true; bool calc_b1 = true; bool calc_z = true; T1 = stan::math::var_value<double>; T2 = stan::math::var_value<double>; T3 = stan::math::var_value<double>; T_z = stan::math::var_value<double>; ScalarT = stan::math::var_value<double>; TupleT = std::tuple<stan::math::var_value<double, void>, stan::math::var_value<double, void>, stan::math::var_value<double, void>, stan::math::var_value<double, void> >]’:\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:307:57:   required from ‘auto stan::math::grad_2F1(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool ReturnSameT = true; T1 = stan::math::var_value<double>; T2 = stan::math::var_value<double>; T3 = stan::math::var_value<double>; T_z = stan::math::var_value<double>; stan::require_t<std::integral_constant<bool, __v> >* <anonymous> = 0]’\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun/grad_inc_beta.hpp:49:51:   required from here\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:192:12: warning: variable ‘pre_mult’ set but not used [-Wunused-but-set-variable]\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/kkoj3jfj/model_kkoj3jfj.cpp: In instantiation of ‘void model_kkoj3jfj_namespace::model_kkoj3jfj::transform_inits_impl(const stan::io::var_context&, VecVar&, std::ostream*) const [with VecVar = std::vector<double, std::allocator<double> >; stan::require_vector_t<T_y>* <anonymous> = 0; std::ostream = std::basic_ostream<char>]’:\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/kkoj3jfj/model_kkoj3jfj.cpp:830:50:   required from here\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/kkoj3jfj/model_kkoj3jfj.cpp:693:11: warning: variable ‘pos__’ set but not used [-Wunused-but-set-variable]\n",
      "       int pos__ = std::numeric_limits<int>::min();\n",
      "           ^~~~~\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/kkoj3jfj/model_kkoj3jfj.cpp: In instantiation of ‘void model_kkoj3jfj_namespace::model_kkoj3jfj::unconstrain_array_impl(const VecVar&, const VecI&, VecVar&, std::ostream*) const [with VecVar = std::vector<double, std::allocator<double> >; VecI = std::vector<int>; stan::require_vector_t<T_y>* <anonymous> = 0; stan::require_vector_like_vt<std::is_integral, VecI>* <anonymous> = 0; std::ostream = std::basic_ostream<char>]’:\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/kkoj3jfj/model_kkoj3jfj.cpp:840:36:   required from here\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/kkoj3jfj/model_kkoj3jfj.cpp:662:11: warning: variable ‘pos__’ set but not used [-Wunused-but-set-variable]\n",
      "       int pos__ = std::numeric_limits<int>::min();\n",
      "           ^~~~~\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/kkoj3jfj/model_kkoj3jfj.cpp: In instantiation of ‘void model_kkoj3jfj_namespace::model_kkoj3jfj::unconstrain_array_impl(const VecVar&, const VecI&, VecVar&, std::ostream*) const [with VecVar = Eigen::Matrix<double, -1, 1>; VecI = std::vector<int>; stan::require_vector_t<T_y>* <anonymous> = 0; stan::require_vector_like_vt<std::is_integral, VecI>* <anonymous> = 0; std::ostream = std::basic_ostream<char>]’:\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/kkoj3jfj/model_kkoj3jfj.cpp:850:36:   required from here\n",
      "/home/latimerk/.cache/httpstan/4.10.1/models/kkoj3jfj/model_kkoj3jfj.cpp:662:11: warning: variable ‘pos__’ set but not used [-Wunused-but-set-variable]\n",
      "In file included from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun.hpp:124:0,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun/multiply.hpp:7,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun/elt_multiply.hpp:9,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun.hpp:55,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev.hpp:10,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math.hpp:19,\n",
      "                 from /home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/model/model_header.hpp:4,\n",
      "                 from /home/latimerk/.cache/httpstan/4.10.1/models/kkoj3jfj/model_kkoj3jfj.cpp:2:\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp: In instantiation of ‘TupleT stan::math::internal::grad_2F1_impl_ab(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool calc_a1 = true; bool calc_a2 = true; bool calc_b1 = true; T1 = double; T2 = double; T3 = double; T_z = double; ScalarT = double; TupleT = std::tuple<double, double, double>]’:\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:205:78:   required from ‘TupleT stan::math::internal::grad_2F1_impl(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool calc_a1 = true; bool calc_a2 = true; bool calc_b1 = true; bool calc_z = true; T1 = double; T2 = double; T3 = double; T_z = double; ScalarT = double; TupleT = std::tuple<double, double, double, double>]’\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:307:57:   required from ‘auto stan::math::grad_2F1(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool ReturnSameT = true; T1 = double; T2 = double; T3 = double; T_z = double; stan::require_t<std::integral_constant<bool, __v> >* <anonymous> = 0]’\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_inc_beta.hpp:37:46:   required from here\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:68:10: warning: unused variable ‘log_precision’ [-Wunused-variable]\n",
      "   double log_precision = log(precision);\n",
      "          ^~~~~~~~~~~~~\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp: In instantiation of ‘TupleT stan::math::internal::grad_2F1_impl_ab(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool calc_a1 = true; bool calc_a2 = true; bool calc_b1 = true; T1 = stan::math::var_value<double>; T2 = stan::math::var_value<double>; T3 = stan::math::var_value<double>; T_z = stan::math::var_value<double>; ScalarT = stan::math::var_value<double>; TupleT = std::tuple<stan::math::var_value<double, void>, stan::math::var_value<double, void>, stan::math::var_value<double, void> >]’:\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:205:78:   required from ‘TupleT stan::math::internal::grad_2F1_impl(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool calc_a1 = true; bool calc_a2 = true; bool calc_b1 = true; bool calc_z = true; T1 = stan::math::var_value<double>; T2 = stan::math::var_value<double>; T3 = stan::math::var_value<double>; T_z = stan::math::var_value<double>; ScalarT = stan::math::var_value<double>; TupleT = std::tuple<stan::math::var_value<double, void>, stan::math::var_value<double, void>, stan::math::var_value<double, void>, stan::math::var_value<double, void> >]’\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:307:57:   required from ‘auto stan::math::grad_2F1(const T1&, const T2&, const T3&, const T_z&, double, int) [with bool ReturnSameT = true; T1 = stan::math::var_value<double>; T2 = stan::math::var_value<double>; T3 = stan::math::var_value<double>; T_z = stan::math::var_value<double>; stan::require_t<std::integral_constant<bool, __v> >* <anonymous> = 0]’\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/rev/fun/grad_inc_beta.hpp:49:51:   required from here\n",
      "/home/latimerk/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/httpstan/include/stan/math/prim/fun/grad_2F1.hpp:68:10: warning: unused variable ‘log_precision’ [-Wunused-variable]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: 29.1s, done.Messages from stanc:\n",
      "Warning: The parameter timeconstant_within_session_C has no priors. This\n",
      "    means either no prior is provided, or the prior(s) depend on data\n",
      "    variables. In the later case, this may be a false positive.\n",
      "Warning: The parameter alpha has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/8000)\n",
      "Sampling:   0% (2/8000)\n",
      "Sampling:   0% (3/8000)\n",
      "Sampling:   0% (4/8000)\n",
      "Sampling:   1% (103/8000)\n",
      "Sampling:   3% (202/8000)\n",
      "Sampling:   4% (301/8000)\n",
      "Sampling:   5% (400/8000)\n",
      "Sampling:   6% (500/8000)\n",
      "Sampling:   8% (600/8000)\n",
      "Sampling:   9% (700/8000)\n",
      "Sampling:  10% (800/8000)\n",
      "Sampling:  11% (900/8000)\n",
      "Sampling:  12% (1000/8000)\n",
      "Sampling:  14% (1100/8000)\n",
      "Sampling:  15% (1200/8000)\n",
      "Sampling:  16% (1300/8000)\n",
      "Sampling:  18% (1400/8000)\n",
      "Sampling:  19% (1500/8000)\n",
      "Sampling:  20% (1600/8000)\n",
      "Sampling:  21% (1700/8000)\n",
      "Sampling:  22% (1800/8000)\n",
      "Sampling:  24% (1900/8000)\n",
      "Sampling:  25% (2000/8000)\n",
      "Sampling:  26% (2100/8000)\n",
      "Sampling:  28% (2200/8000)\n",
      "Sampling:  29% (2300/8000)\n",
      "Sampling:  30% (2400/8000)\n",
      "Sampling:  31% (2500/8000)\n",
      "Sampling:  32% (2600/8000)\n",
      "Sampling:  34% (2700/8000)\n",
      "Sampling:  35% (2800/8000)\n",
      "Sampling:  36% (2900/8000)\n",
      "Sampling:  38% (3000/8000)\n",
      "Sampling:  39% (3100/8000)\n",
      "Sampling:  40% (3200/8000)\n",
      "Sampling:  41% (3300/8000)\n",
      "Sampling:  42% (3400/8000)\n",
      "Sampling:  44% (3500/8000)\n",
      "Sampling:  45% (3600/8000)\n",
      "Sampling:  46% (3701/8000)\n",
      "Sampling:  48% (3801/8000)\n",
      "Sampling:  48% (3802/8000)\n",
      "Sampling:  49% (3902/8000)\n",
      "Sampling:  49% (3903/8000)\n",
      "Sampling:  50% (4003/8000)\n",
      "Sampling:  50% (4004/8000)\n",
      "Sampling:  51% (4103/8000)\n",
      "Sampling:  53% (4202/8000)\n",
      "Sampling:  54% (4301/8000)\n",
      "Sampling:  55% (4400/8000)\n",
      "Sampling:  56% (4500/8000)\n",
      "Sampling:  58% (4600/8000)\n",
      "Sampling:  59% (4700/8000)\n",
      "Sampling:  60% (4800/8000)\n",
      "Sampling:  61% (4900/8000)\n",
      "Sampling:  62% (5000/8000)\n",
      "Sampling:  64% (5100/8000)\n",
      "Sampling:  65% (5200/8000)\n",
      "Sampling:  66% (5300/8000)\n",
      "Sampling:  68% (5400/8000)\n",
      "Sampling:  69% (5500/8000)\n",
      "Sampling:  70% (5600/8000)\n",
      "Sampling:  71% (5700/8000)\n",
      "Sampling:  72% (5800/8000)\n",
      "Sampling:  74% (5900/8000)\n",
      "Sampling:  75% (6000/8000)\n",
      "Sampling:  76% (6100/8000)\n",
      "Sampling:  78% (6200/8000)\n",
      "Sampling:  79% (6300/8000)\n",
      "Sampling:  80% (6400/8000)\n",
      "Sampling:  81% (6500/8000)\n",
      "Sampling:  82% (6600/8000)\n",
      "Sampling:  84% (6700/8000)\n",
      "Sampling:  85% (6800/8000)\n",
      "Sampling:  86% (6900/8000)\n",
      "Sampling:  88% (7000/8000)\n",
      "Sampling:  89% (7100/8000)\n",
      "Sampling:  90% (7200/8000)\n",
      "Sampling:  91% (7300/8000)\n",
      "Sampling:  92% (7400/8000)\n",
      "Sampling:  94% (7500/8000)\n",
      "Sampling:  95% (7600/8000)\n",
      "Sampling:  96% (7700/8000)\n",
      "Sampling:  98% (7800/8000)\n",
      "Sampling:  99% (7900/8000)\n",
      "Sampling: 100% (8000/8000)\n",
      "Sampling: 100% (8000/8000), done.\n",
      "Messages received during sampling:\n",
      "  Gradient evaluation took 0.028741 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 287.41 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 0.030245 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 302.45 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 0.030792 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 307.92 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Gradient evaluation took 0.033572 seconds\n",
      "  1000 transitions using 10 leapfrog steps per transition would take 335.72 seconds.\n",
      "  Adjust your expectations accordingly!\n",
      "  Informational Message: The current Metropolis proposal is about to be rejected because of the following issue:\n",
      "  Exception: gamma_lpdf: Random variable is inf, but must be positive finite! (in '/tmp/httpstan_w1ndhaej/model_kkoj3jfj.stan', line 76, column 4 to column 108)\n",
      "  If this warning occurs sporadically, such as for highly constrained variable types like covariance matrices, then the sampler is fine,\n",
      "  but if this warning occurs often then your model may be either severely ill-conditioned or misspecified.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject B1 in group uniform, cd = 0, nb = 0\n",
      "fitting with ['A1', 'C1', 'D1', 'E1', 'F1', 'G1', 'H1', 'I1', 'J1'], cd = 0, nb = 0\n",
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning: The parameter timeconstant_within_session_C has no priors. This\n",
      "    means either no prior is provided, or the prior(s) depend on data\n",
      "    variables. In the later case, this may be a false positive.\n",
      "Warning: The parameter alpha has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/8000)\n",
      "Sampling:   0% (2/8000)\n",
      "Sampling:   0% (3/8000)\n",
      "Sampling:   0% (4/8000)\n",
      "Sampling:   1% (103/8000)\n",
      "Sampling:   3% (202/8000)\n",
      "Sampling:   4% (301/8000)\n",
      "Sampling:   5% (400/8000)\n",
      "Sampling:   6% (500/8000)\n",
      "Sampling:   8% (600/8000)\n",
      "Sampling:   9% (700/8000)\n",
      "Sampling:  10% (800/8000)\n",
      "Sampling:  11% (900/8000)\n",
      "Sampling:  12% (1000/8000)\n",
      "Sampling:  14% (1100/8000)\n",
      "Sampling:  15% (1200/8000)\n",
      "Sampling:  16% (1300/8000)\n",
      "Sampling:  18% (1400/8000)\n",
      "Sampling:  19% (1500/8000)\n",
      "Sampling:  20% (1600/8000)\n",
      "Sampling:  21% (1700/8000)\n",
      "Sampling:  22% (1800/8000)\n",
      "Sampling:  24% (1900/8000)\n",
      "Sampling:  25% (2000/8000)\n",
      "Sampling:  26% (2100/8000)\n",
      "Sampling:  28% (2200/8000)\n",
      "Sampling:  29% (2300/8000)\n",
      "Sampling:  30% (2400/8000)\n",
      "Sampling:  31% (2500/8000)\n",
      "Sampling:  32% (2600/8000)\n",
      "Sampling:  34% (2700/8000)\n",
      "Sampling:  35% (2800/8000)\n",
      "Sampling:  36% (2900/8000)\n",
      "Sampling:  38% (3000/8000)\n",
      "Sampling:  39% (3100/8000)\n",
      "Sampling:  40% (3200/8000)\n",
      "Sampling:  41% (3300/8000)\n",
      "Sampling:  42% (3400/8000)\n",
      "Sampling:  44% (3500/8000)\n",
      "Sampling:  45% (3600/8000)\n",
      "Sampling:  46% (3700/8000)\n",
      "Sampling:  46% (3701/8000)\n",
      "Sampling:  48% (3802/8000)\n",
      "Sampling:  49% (3902/8000)\n",
      "Sampling:  50% (4002/8000)\n",
      "Sampling:  50% (4003/8000)\n",
      "Sampling:  50% (4004/8000)\n",
      "Sampling:  51% (4103/8000)\n",
      "Sampling:  53% (4202/8000)\n",
      "Sampling:  54% (4301/8000)\n",
      "Sampling:  55% (4400/8000)\n",
      "Sampling:  56% (4500/8000)\n",
      "Sampling:  58% (4600/8000)\n",
      "Sampling:  59% (4700/8000)\n",
      "Sampling:  60% (4800/8000)\n",
      "Sampling:  61% (4900/8000)\n",
      "Sampling:  62% (5000/8000)\n",
      "Sampling:  64% (5100/8000)\n",
      "Sampling:  65% (5200/8000)\n",
      "Sampling:  66% (5300/8000)\n",
      "Sampling:  68% (5400/8000)\n",
      "Sampling:  69% (5500/8000)\n",
      "Sampling:  70% (5600/8000)\n",
      "Sampling:  71% (5700/8000)\n",
      "Sampling:  72% (5800/8000)\n",
      "Sampling:  74% (5900/8000)\n",
      "Sampling:  75% (6000/8000)\n",
      "Sampling:  76% (6100/8000)\n",
      "Sampling:  78% (6200/8000)\n",
      "Sampling:  79% (6300/8000)\n",
      "Sampling:  80% (6400/8000)\n",
      "Sampling:  81% (6500/8000)\n",
      "Sampling:  82% (6600/8000)\n",
      "Sampling:  84% (6700/8000)\n",
      "Sampling:  85% (6800/8000)\n",
      "Sampling:  86% (6900/8000)\n",
      "Sampling:  88% (7000/8000)\n",
      "Sampling:  89% (7100/8000)\n",
      "Sampling:  90% (7200/8000)\n",
      "Sampling:  91% (7300/8000)\n",
      "Sampling:  92% (7400/8000)"
     ]
    }
   ],
   "source": [
    "if(session_numbers is None):\n",
    "    fit_file = f\"{results_directory}/fits_trials_{number_of_trials}\"\n",
    "    fit_summary_file = f\"{results_directory}/fit_summary_trials_{number_of_trials}\"\n",
    "    seed_offset = number_of_trials\n",
    "    xval_file = f\"{results_directory}/xval_trials_{number_of_trials}\"\n",
    "else:\n",
    "    start_session = np.min(session_numbers)\n",
    "    end_session = np.max(session_numbers)\n",
    "    fit_file = f\"{results_directory}/fits_session_{start_session}\"\n",
    "    fit_summary_file = f\"{results_directory}/fit_summary_session_{start_session}\"\n",
    "    if(end_session != start_session):\n",
    "        fit_file += f\"_to_{start_session}\"\n",
    "        fit_summary_file  += f\"_to_{start_session}\"\n",
    "    seed_offset = start_session\n",
    "    xval_file = f\"{results_directory}/xval_session_{start_session}\"\n",
    "\n",
    "\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file += f\".pkl\"\n",
    "xval_file += f\".pkl\"\n",
    "\n",
    "\n",
    "if(not os.path.isfile(xval_file) or overwrite_existing_results):\n",
    "    # data_fits = pd.DataFrame()\n",
    "    # data_fit_metrics = pd.DataFrame()\n",
    "    xval_df = pd.DataFrame()\n",
    "    for nback_depth in range(2):\n",
    "        for context_depth in range(3):\n",
    "            for subject_index, subject in enumerate(subject_labels):\n",
    "                population = population_labels[subject_index];\n",
    "                print(f\"subject {subject} in group {population}, cd = {context_depth}, nb = {nback_depth}\")\n",
    "\n",
    "                stan_seed = (subject_index+1) * 1000 + seed_offset\n",
    "                sequences_c          = [xx for (xx,yy,zz) in zip(sequences,         subject_labels, population_labels) if ((yy != subject) and (zz == population)) ]\n",
    "                session_types_c      = [xx for (xx,yy,zz) in zip(session_types,     subject_labels, population_labels) if ((yy != subject) and (zz == population)) ]\n",
    "                subject_labels_c     = [xx for (xx,yy,zz) in zip(subject_labels,    subject_labels, population_labels) if ((yy != subject) and (zz == population)) ]\n",
    "                population_labels_c  = [xx for (xx,yy,zz) in zip(population_labels, subject_labels, population_labels) if ((yy != subject) and (zz == population)) ]\n",
    "                subject_label = subject\n",
    "                print(f\"fitting with {subject_labels_c}, cd = {context_depth}, nb = {nback_depth}\")\n",
    "\n",
    "                fit_df, summary_df = run_fit(stan_seed, sequences_c, session_types_c, subject_labels_c, population_labels_c, subject_label, context_depth, nback_depth)\n",
    "\n",
    "                # data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "                # data_fits        = pd.concat([data_fits,fit_df], copy=False)'\n",
    "\n",
    "                test_seq = sequences[subject_labels.index(subject)]\n",
    "                ts = xval_sequence(test_seq, fit_df, context_depth, nback_depth)\n",
    "                df_c = pd.DataFrame({\"log_likelihood\" : ts, \"subject\" : subject, \"train_condition\" : \"LOO\", \"nback\" : nback_depth, \"context\" : context_depth})\n",
    "                xval_df        = pd.concat([xval_df,df_c], copy=False)\n",
    "            for group_index, group in enumerate(groups):\n",
    "                print(f\"population {group}\")\n",
    "\n",
    "                stan_seed = (group_index+1) * 10000 + seed_offset\n",
    "                sequences_c          = [xx for (xx,yy,zz) in zip(sequences,         subject_labels, population_labels) if (zz == group) ]\n",
    "                session_types_c      = [xx for (xx,yy,zz) in zip(session_types,     subject_labels, population_labels) if (zz == group) ]\n",
    "                subject_labels_c     = [xx for (xx,yy,zz) in zip(subject_labels,    subject_labels, population_labels) if (zz == group) ]\n",
    "                population_labels_c  = [xx for (xx,yy,zz) in zip(population_labels, subject_labels, population_labels) if (zz == group) ]\n",
    "                subject_label = f\"POPULATION_{group}\"\n",
    "                print(f\"fitting with {subject_labels_c}\")\n",
    "\n",
    "                fit_df, summary_df = run_fit(stan_seed, sequences_c, session_types_c, subject_labels_c, population_labels_c, subject_label, context_depth, nback_depth)\n",
    "\n",
    "                # data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "                # data_fits        = pd.concat([data_fits,fit_df], copy=False)'\n",
    "\n",
    "                for test_seq, subject in zip(sequences_c, subject_labels_c):\n",
    "                    ts = xval_sequence(test_seq, fit_df, context_depth, nback_depth)\n",
    "                    df_c = pd.DataFrame({\"log_likelihood\" : ts, \"subject\" : subject, \"train_condition\" : \"train\", \"nback\" : nback_depth, \"context\" : context_depth})\n",
    "                    xval_df        = pd.concat([xval_df,df_c], copy=False)\n",
    "\n",
    "                sequences_tst          = [(xx,yy) for (xx,yy,zz) in zip(sequences,      subject_labels, population_labels) if (zz != group)]\n",
    "\n",
    "                for test_seq, subject in sequences_tst:\n",
    "                    ts = xval_sequence(test_seq, fit_df, context_depth, nback_depth)\n",
    "                    df_c = pd.DataFrame({\"log_likelihood\" : ts, \"subject\" : subject, \"train_condition\" : \"cross\", \"nback\" : nback_depth, \"context\" : context_depth})\n",
    "                    xval_df        = pd.concat([xval_df,df_c], copy=False)\n",
    "\n",
    "\n",
    "    # data_fits.to_pickle(fit_file)\n",
    "    # data_fit_metrics.to_pickle(fit_summary_file)\n",
    "    xval_df.to_pickle(xval_file)\n",
    "else:\n",
    "    print(\"fit file found\")\n",
    "    xval_df = pd.read_pickle(xval_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# sns.boxplot(data=xval_df, x=\"subject\", y=\"log_likelihood\", hue=\"train_condition\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaiYuLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
