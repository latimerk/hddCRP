{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hddCRP.simulations\n",
    "import hddCRP.modelFittingSequential\n",
    "import hddCRP.behaviorDataHandlers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_directory = \"Results/Simulations/\"\n",
    "if(not os.path.exists(results_directory)):\n",
    "    os.makedirs(results_directory)\n",
    "    \n",
    "simulation_id = 0; # for naming file\n",
    "\n",
    "overwrite_existing_results = True\n",
    "\n",
    "run_range = range(0,1)\n",
    "\n",
    "num_warmup_samples =500\n",
    "num_samples = 500\n",
    "\n",
    "initialize_fit_with_real_connections = False;\n",
    "\n",
    "prior_scales = None\n",
    "prior_shapes = None\n",
    "\n",
    "if(simulation_id == 0):\n",
    "    depth  = 3; # look 2 actions in the past\n",
    "    alphas = [10,5,5] # concentration parameters: per depth in the hddCRP tree. alphas[0] first level (no action context), alphas[1] is the second (for regularizing p(y_t | y_{t-1})), etc...\n",
    "    between_session_time_constants = np.array([[ 1]]) # units = sessions\n",
    "    within_session_time_constant = [40] # units = actions\n",
    "    nback_scales = [0.8, 1.2] # units = actions\n",
    "\n",
    "    session_length = lambda run_idx, block_idx : 50  # trials per session\n",
    "    num_sessions   = lambda run_idx, block_idx : 1 # trials per session\n",
    "    num_models     = lambda run_idx, block_idx : (block_idx) # trials per session\n",
    "\n",
    "    action_labels = [0,1,2] \n",
    "    maze_symbols = ['A']\n",
    "    uniform_prior = False\n",
    "    min_blocks_per_type = 1\n",
    "    max_blocks_per_type = 2;\n",
    "    prior_scales = {\"alpha\" : 5, \"tau_within\" : 25, \"tau_between\" : 5, \"nback\" : 1/20}\n",
    "    prior_shapes = {\"alpha\" : 2, \"tau_within\" :  2, \"tau_between\" : 2, \"nback\" : 20}\n",
    "    fit_nback_scales = True\n",
    "    single_concentration_parameter = False\n",
    "    fit_depth = 3\n",
    "elif(simulation_id == 0):\n",
    "    depth  = 3; # look 2 actions in the past\n",
    "    alphas = [5,10,10] # concentration parameters: per depth in the hddCRP tree. alphas[0] first level (no action context), alphas[1] is the second (for regularizing p(y_t | y_{t-1})), etc...\n",
    "    between_session_time_constants = np.array([[ 1]]) # units = sessions\n",
    "    within_session_time_constant = [20] # units = actions\n",
    "    nback_scales = [1.2, 0.8] # units = actions\n",
    "\n",
    "    session_length = lambda run_idx, block_idx : 50  # trials per session\n",
    "    num_sessions   = lambda run_idx, block_idx : 1 # trials per session\n",
    "    num_models     = lambda run_idx, block_idx : (block_idx) # trials per session\n",
    "\n",
    "    action_labels = [0,1,2] \n",
    "    maze_symbols = ['A']\n",
    "    uniform_prior = False\n",
    "    min_blocks_per_type = 1\n",
    "    max_blocks_per_type = 2;\n",
    "    prior_scales = {\"alpha\" : 5, \"tau_within\" : 25, \"tau_between\" : 5, \"nback\" : 1/20}\n",
    "    prior_shapes = {\"alpha\" : 2, \"tau_within\" :  2, \"tau_between\" : 2, \"nback\" : 20}\n",
    "    fit_nback_scales = True\n",
    "    single_concentration_parameter = False\n",
    "    fit_depth = 3\n",
    "\n",
    "max_blocks_per_type = 10;\n",
    "blocks_range = range(min_blocks_per_type,max_blocks_per_type+1);\n",
    "\n",
    "true_parameters = {}\n",
    "alpha_strs = [\"no\", \"one_back\", \"two_back\", \"three_back\"]\n",
    "for dd in range(depth):\n",
    "    true_parameters[\"alpha_concentration_\" + alpha_strs[dd] + \"_context\"] = alphas[dd]\n",
    "for aa_i, aa in enumerate(maze_symbols): \n",
    "    true_parameters[\"within_session_\" + aa + \"_time_constant\"] = within_session_time_constant[aa_i]\n",
    "\n",
    "if(max_blocks_per_type > 1):\n",
    "    for aa_i, aa in enumerate(maze_symbols):\n",
    "        if(num_sessions(run_range[0], blocks_range[0]) > 1):\n",
    "            true_parameters[aa + \"_to_\" + aa + \"_session_time_constant\"] = between_session_time_constants[aa_i,aa_i]\n",
    "\n",
    "\n",
    "        for bb_i, bb in enumerate(maze_symbols[aa_i+1:]):\n",
    "            true_parameters[aa + \"_to_\" + bb + \"_session_time_constant\"] = between_session_time_constants[aa_i,bb_i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0 in [0, 0]\n",
      "block 1 in [1, 10]\n",
      "session_lengths: [50]\n",
      "session_labels : ['A']\n",
      "n_sims:          1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "create_hddCRP() missing 1 required positional argument: 'block_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(n_sims \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     24\u001b[0m     seqs, connection_data \u001b[38;5;241m=\u001b[39m hddCRP\u001b[38;5;241m.\u001b[39msimulations\u001b[38;5;241m.\u001b[39msimulate_sequential_hddCRP(session_lengths, session_labels, action_labels, depth, rng_sim, alphas, \n\u001b[1;32m     25\u001b[0m             between_session_time_constants \u001b[38;5;241m=\u001b[39m between_session_time_constants, within_session_time_constant \u001b[38;5;241m=\u001b[39m within_session_time_constant, nback_scales\u001b[38;5;241m=\u001b[39mnback_scales)\n\u001b[0;32m---> 26\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mhddCRP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbehaviorDataHandlers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_hddCRP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_nback_scales\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_nback_scales\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m     models \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: create_hddCRP() missing 1 required positional argument: 'block_ids'"
     ]
    }
   ],
   "source": [
    "\n",
    "for run_idx in run_range:\n",
    "    print(\"run \" + str(run_idx) + \" in [\" + str(run_range[0]) + \", \" + str(run_range[-1]) + \"]\")\n",
    "    for block_idx in blocks_range:\n",
    "        print(\"block \" + str(block_idx) + \" in [\" + str(blocks_range[0]) + \", \" + str(blocks_range[-1]) + \"]\")\n",
    "        filename = \"{results_directory}/Sim_{sim_num}_block_{block_idx}_run_{run_idx}.pkl\".format(results_directory=results_directory, sim_num=simulation_id, block_idx=block_idx, run_idx=run_idx)\n",
    "        if(not os.path.isfile(filename) or overwrite_existing_results):\n",
    "            rng_seed_sim = block_idx*0 + 100 + 10000*run_idx;\n",
    "            rng_seed_fit = block_idx*0 + 200 + 10000*run_idx;\n",
    "            rng_sim = np.random.Generator(np.random.MT19937(rng_seed_sim))\n",
    "            rng_fit = np.random.Generator(np.random.MT19937(rng_seed_fit))\n",
    "\n",
    "\n",
    "            session_lengths = [session_length(run_idx, block_idx)] * (len(maze_symbols) * num_sessions(run_idx, block_idx))\n",
    "            session_labels = [];\n",
    "            for aa in maze_symbols:\n",
    "                session_labels += [aa] * num_sessions(run_idx, block_idx)  # which maze\n",
    "            n_sims = num_models(run_idx, block_idx);\n",
    "            print(\"session_lengths: \" + str(session_lengths))\n",
    "            print(\"session_labels : \" + str(session_labels))\n",
    "            print(\"n_sims:          \" + str(n_sims))\n",
    "\n",
    "\n",
    "            if(n_sims == 1):\n",
    "                seqs, connection_data = hddCRP.simulations.simulate_sequential_hddCRP(session_lengths, session_labels, action_labels, depth, rng_sim, alphas, \n",
    "                        between_session_time_constants = between_session_time_constants, within_session_time_constant = within_session_time_constant, nback_scales=nback_scales)\n",
    "                model = hddCRP.behaviorDataHandlers.create_hddCRP(seqs, session_labels, rng=rng_fit, depth=depth, fit_nback_scales=fit_nback_scales)\n",
    "\n",
    "            else:\n",
    "                models = []\n",
    "                connection_data = []\n",
    "                for sim_num in range(n_sims):\n",
    "                    seqs, connection_data_c = hddCRP.simulations.simulate_sequential_hddCRP(session_lengths, session_labels, action_labels, depth, rng_sim, alphas, \n",
    "                            between_session_time_constants = between_session_time_constants, within_session_time_constant = within_session_time_constant, nback_scales=nback_scales)\n",
    "                    model = hddCRP.behaviorDataHandlers.create_hddCRP(seqs, session_labels, rng=rng_fit, depth=depth, fit_nback_scales=fit_nback_scales)\n",
    "                    models += [model]\n",
    "                    connection_data += [connection_data_c]\n",
    "\n",
    "            simulation_info = {\"rng_seed_simulation\" : rng_seed_sim, \"rng_seed_fitting\" : rng_seed_fit, \"rng_type\" : \"MT19937\",\n",
    "                            \"session_lengths\" : session_lengths, \"session_labels\" : session_labels, \"action_labels\" : action_labels,\n",
    "                            \"seqs\" : seqs, \"connection_data\" : connection_data}\n",
    "\n",
    "\n",
    "            tau_names = [str(xx) for xx in model.weight_param_labels]\n",
    "            alphas_names = [\"alpha_concentration_no_context\", \"alpha_concentration_one_back_context\", \"alpha_concentration_two_back_context\"]\n",
    "            if(n_sims == 1):\n",
    "                model, samples, step_size_settings = hddCRP.behaviorDataHandlers.sample_model_for_maze_data(model, num_samples=num_samples, \n",
    "                                num_warmup_samples=num_warmup_samples, print_every=2500, uniform_prior=uniform_prior, prior_shapes=prior_shapes, prior_scales=prior_scales, \n",
    "                                single_concentration_parameter=single_concentration_parameter)\n",
    "            else:\n",
    "                models, samples, step_size_settings = hddCRP.behaviorDataHandlers.sample_population_model_for_maze_data(models, num_samples=num_samples, \n",
    "                                num_warmup_samples=num_warmup_samples, print_every=2500, uniform_prior=uniform_prior, prior_shapes=prior_shapes, prior_scales=prior_scales, \n",
    "                                single_concentration_parameter=single_concentration_parameter)\n",
    "\n",
    "            if(depth > fit_depth):\n",
    "                ag =  np.ones((samples[\"alphas\"].shape[0], depth-fit_depth));\n",
    "                ag.fill(np.inf)\n",
    "                samples[\"alphas\"] = np.concatenate([samples[\"alphas\"], ag], axis=1)\n",
    "\n",
    "            MCMC_info = {\"initialized_with_true_connections\" : initialize_fit_with_real_connections,\n",
    "                        \"step_size_settings\" : step_size_settings.to_dict(),\n",
    "                        \"num_warmup_samples\" : num_warmup_samples,\n",
    "                        \"num_samples\" : num_samples,\n",
    "                        \"prior_shapes\" : prior_shapes,\n",
    "                        \"prior_scales\" : prior_scales}\n",
    "            samples[\"tau_parameter_names\"] = tau_names\n",
    "            samples[\"alphas_names\"] = alphas_names[:depth]\n",
    "            \n",
    "            # save results to filename\n",
    "            with open(filename, \"wb\") as results_file:\n",
    "                results_data = {\"true_parameters\" : true_parameters,\n",
    "                                \"simulation_info\" : simulation_info,\n",
    "                                \"MCMC_info\" : MCMC_info,\n",
    "                                \"samples\" : samples}\n",
    "                pickle.dump(results_data, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_data = np.zeros((num_samples, len(run_range)*len(true_parameters)*len(block_range)))\n",
    "empty_data.fill(np.nan)\n",
    "parameters = pd.DataFrame(empty_data,\n",
    "                  columns=pd.MultiIndex.from_product([true_parameters.keys(), block_range, run_range], names=[\"parameter\", \"sessions per maze\", \"run\"]))\n",
    "parameters.index.name='sample'\n",
    "\n",
    "# plot results: MCMC credible intervals for each parameter as a function of N_blocks_per_type\n",
    "print(\"Metropolis-Hastings acceptance rate and step size:\")\n",
    "for run_idx in run_range:\n",
    "    for block_idx in blocks_range:\n",
    "        filename = \"{results_directory}/Sim_{sim_num}_size_{N_blocks_per_type}_run_{run_num}.pkl\".format(results_directory=results_directory, sim_num=simulation_id, N_blocks_per_type=block_idx, run_num=run_idx)\n",
    "        if(not os.path.isfile(filename)):\n",
    "            raise RuntimeError(\"Results file not found: \" + filename)\n",
    "            # throw error\n",
    "        \n",
    "        # load file\n",
    "        with open(filename, \"rb\") as results_file:\n",
    "            results = pickle.load(results_file)\n",
    "\n",
    "            # '''\n",
    "            # Make sure all the files loaded are correct\n",
    "            # '''\n",
    "\n",
    "            # # check for correct results fields\n",
    "            # expected_fields = [\"true_parameters\", \"simulation_info\", \"MCMC_info\", \"samples\"]\n",
    "            # if(not isinstance(results, dict) or not np.all(np.isin(expected_fields, list(results.keys())))):\n",
    "            #     raise ValueError(\"File \" + filename + \" does not contain expected results fields\")\n",
    "            \n",
    "            # session_lengths = [session_length(run_idx)] * (len(maze_symbols) * N_blocks_per_type)\n",
    "            # session_labels = [];\n",
    "            # for aa in maze_symbols:\n",
    "            #     session_labels += [aa] * N_blocks_per_type  # which maze\n",
    "            # if(results[\"simulation_info\"][\"session_lengths\"] != session_lengths):\n",
    "            #     raise ValueError(\"File \" + filename + \" does not contain expected session lengths\")\n",
    "            # if(results[\"simulation_info\"][\"session_labels\"] != session_labels):\n",
    "            #     raise ValueError(\"File \" + filename + \" does not contain expected session labels\")\n",
    "            # if(results[\"simulation_info\"][\"action_labels\"] != action_labels):\n",
    "            #     raise ValueError(\"File \" + filename + \" does not contain expected action labels\")\n",
    "\n",
    "\n",
    "            # #results[\"samples\"][\"alphas_names\"] = results[\"samples\"][\"alphas_names\"][:depth]\n",
    "\n",
    "            # # check if samples matches (if greater than expected, raise a warning; it less, raise an error)\n",
    "            # expected_fields_samples = [\"log_taus\", \"alphas\", \"accepted\", \"num_warmup_samples\", \"tau_parameter_names\", \"alphas_names\"]\n",
    "            # if(not isinstance(results[\"samples\"], dict) or not np.all(np.isin(expected_fields_samples, list(results[\"samples\"].keys())))):\n",
    "            #     raise ValueError(\"File \" + filename + \" does not contain expected results['samples'] fields\")\n",
    "            \n",
    "            # num_samples_found = min(results[\"samples\"][\"log_taus\"].shape[0], results[\"samples\"][\"alphas\"].shape[0]) - results[\"samples\"][\"num_warmup_samples\"]\n",
    "            # if(num_samples_found < num_samples):\n",
    "            #     raise ValueError(\"File \" + filename + \" does not contain expected number of samples in results['samples']. Found \" + str(num_samples_found) + \". Expected \" + str(num_samples) + \".\")\n",
    "\n",
    "            # # check if true params match, if not, raise error\n",
    "            # if(not np.all(np.isin(list(true_parameters.keys()), results[\"samples\"][\"tau_parameter_names\"] + results[\"samples\"][\"alphas_names\"]))):\n",
    "            #     raise ValueError(\"File \" + filename + \" does not contain expected parameters in results['samples']\")\n",
    "            # if(not np.all(np.isin(list(true_parameters.keys()), list(results[\"true_parameters\"].keys()))) or not np.all(np.isin(list(results[\"true_parameters\"].keys()), list(true_parameters.keys())))):\n",
    "            #    raise ValueError(\"File \" + filename + \" does not contain expected parameters in results['true_parameters']\")\n",
    "            \n",
    "            # for p_name in true_parameters.keys():\n",
    "            #    if(true_parameters[p_name] != results[\"true_parameters\"][p_name]):\n",
    "            #        raise ValueError(\"File \" + filename + \" does not contain expected parameter value results['true_parameters'][\" + p_name + \"]\")\n",
    "\n",
    "            # load samples from each parameter into dataframe (multi-index: name of param and run number)\n",
    "            s_index = range(results[\"samples\"][\"num_warmup_samples\"], results[\"samples\"][\"num_warmup_samples\"] + num_samples)\n",
    "            for ii, p_name in enumerate(results[\"samples\"][\"tau_parameter_names\"] ):\n",
    "                \n",
    "                parameters.loc[:,(p_name,block_idx,run_idx)] = np.exp(results[\"samples\"][\"log_taus\"][s_index,ii])\n",
    "            for ii, p_name in enumerate(results[\"samples\"][\"alphas_names\"] ):\n",
    "                parameters.loc[:,(p_name,block_idx,run_idx)] = results[\"samples\"][\"alphas\"][s_index,ii]\n",
    "\n",
    "            print(\"Run \" + str(run_idx) + \", num blocks \" + str(block_idx) + \": rate = \" + str(np.mean(results[\"samples\"][\"accepted\"][s_index])) + \", step size = \" + str(np.sqrt(results[\"MCMC_info\"][\"step_size_settings\"][\"step_size_fixed\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_s = parameters.stack([1,2]).reset_index()    \n",
    "n_cols = 2\n",
    "n_rows = int(np.ceil(len(true_parameters)/float(n_cols)))\n",
    "plt.figure(figsize=(n_cols*8,n_rows*4))\n",
    "\n",
    "for ii, p_name in enumerate(true_parameters.keys()):\n",
    "    plt.subplot(n_rows, n_cols, ii+1)\n",
    "    # for each parameter in the data frame, make a plot of 95% CI and mean over time vs. true params\n",
    "    pp = sns.lineplot(x=\"sessions per maze\", y=p_name,\n",
    "                hue=\"run\", errorbar=(\"pi\",95),\n",
    "                data=parameters_s)\n",
    "    plt.plot([min_blocks_per_type,max_blocks_per_type], [true_parameters[p_name], true_parameters[p_name]], \"k:\")\n",
    "    pp.set_xticks(range(min_blocks_per_type,max_blocks_per_type+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = samples[\"transition_probabilities\"][\"probabilities\"].squeeze();\n",
    "xx.shape\n",
    "\n",
    "print(samples[\"transition_probabilities\"][\"contexts\"])\n",
    "print(model._predictive_transition_probability_setup[\"groups_numbers_each_level\"])\n",
    "model.num_groups\n",
    "\n",
    "iis = [np.where(model._groupings_compact[:,-1] == xx)[0][0] for xx in range(model.num_groups[-1])]\n",
    "\n",
    "print(model._groupings[iis,:])\n",
    "model._Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,10000,5),xx[::5,0,1::3].squeeze())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa7646fadbe57c277d76ff36de8f181b6360ae43924dda8e36f9c735fd43eb1d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit ('JaiYuLab': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
