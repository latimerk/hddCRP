{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hddCRP.simulations\n",
    "import hddCRP.modelFitting\n",
    "import hddCRP.behaviorDataHandlers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_directory = \"Results/Simulations\"\n",
    "if(not os.path.exists(results_directory)):\n",
    "    os.makedirs(results_directory)\n",
    "    \n",
    "simulation_id = 0; # for naming file\n",
    "\n",
    "overwrite_existing_results = True\n",
    "\n",
    "num_runs = 2;\n",
    "num_warmup_samples = 5000\n",
    "num_samples = 10000\n",
    "max_blocks_per_type = 10;\n",
    "\n",
    "initialize_fit_with_real_connections = False;\n",
    "\n",
    "depth  = 3; # look 2 actions in the past\n",
    "alphas = [2,10,20] # concentration parameters: per depth in the hddCRP tree. alphas[0] first level (no action context), alphas[1] is the second (for regularizing p(y_t | y_{t-1})), etc...\n",
    "between_session_time_constants = np.array([[ 5, 2],\n",
    "                                            [2, 5]]) # units = sessions\n",
    "within_session_time_constant = [30,20] # units = actions\n",
    "true_parameters = {\"within_session_time_constant\" : within_session_time_constant,\n",
    "                   \"A_to_A_session_time_constant\" : between_session_time_constants[0,0],\n",
    "                   \"A_to_B_session_time_constant\" : between_session_time_constants[0,1],\n",
    "                   \"B_to_B_session_time_constant\" : between_session_time_constants[1,1],\n",
    "                   \"alpha_concentration_no_context\" : alphas[0],\n",
    "                   \"alpha_concentration_one_back_context\" : alphas[1],\n",
    "                   \"alpha_concentration_two_back_context\" : alphas[2]}\n",
    "session_length = 60 # trials per session\n",
    "action_labels = [0,1,2] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m tau_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(xx) \u001b[38;5;28;01mfor\u001b[39;00m xx \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mweight_param_labels]\n\u001b[1;32m     23\u001b[0m alphas_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha_concentration_no_context\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha_concentration_one_back_context\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha_concentration_two_back_context\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 24\u001b[0m model, samples, step_size_settings \u001b[38;5;241m=\u001b[39m \u001b[43mhddCRP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbehaviorDataHandlers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_model_for_maze_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_warmup_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_warmup_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m MCMC_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitialized_with_true_connections\u001b[39m\u001b[38;5;124m\"\u001b[39m : initialize_fit_with_real_connections,\n\u001b[1;32m     27\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep_size_settings\u001b[39m\u001b[38;5;124m\"\u001b[39m : step_size_settings\u001b[38;5;241m.\u001b[39mto_dict(),\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_warmup_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m : num_warmup_samples,\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m : num_samples}\n\u001b[1;32m     30\u001b[0m samples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtau_parameter_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tau_names\n",
      "File \u001b[0;32m~/gitCode/hddCRP/src/hddCRP/behaviorDataHandlers.py:315\u001b[0m, in \u001b[0;36msample_model_for_maze_data\u001b[0;34m(hddcrp, num_samples, num_warmup_samples, uniform_prior)\u001b[0m\n\u001b[1;32m    308\u001b[0m samples \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_acceptance_probability\u001b[39m\u001b[38;5;124m\"\u001b[39m : np\u001b[38;5;241m.\u001b[39mzeros((num_samples_total)),\n\u001b[1;32m    309\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccepted\u001b[39m\u001b[38;5;124m\"\u001b[39m : np\u001b[38;5;241m.\u001b[39mzeros((num_samples_total),dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m),\n\u001b[1;32m    310\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malphas\u001b[39m\u001b[38;5;124m\"\u001b[39m   : np\u001b[38;5;241m.\u001b[39mzeros((num_samples_total,hddcrp\u001b[38;5;241m.\u001b[39malpha\u001b[38;5;241m.\u001b[39msize)),\n\u001b[1;32m    311\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_taus\u001b[39m\u001b[38;5;124m\"\u001b[39m : np\u001b[38;5;241m.\u001b[39mzeros((num_samples_total,hddcrp\u001b[38;5;241m.\u001b[39mweight_params\u001b[38;5;241m.\u001b[39msize)),\n\u001b[1;32m    312\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_warmup_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m : num_warmup_samples}\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ss \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples_total):\n\u001b[0;32m--> 315\u001b[0m     \u001b[43mhddcrp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_gibbs_sweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     sigma2 \u001b[38;5;241m=\u001b[39m step_size_settings\u001b[38;5;241m.\u001b[39mstep_size_fixed \u001b[38;5;28;01mif\u001b[39;00m ss \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_warmup_samples \u001b[38;5;28;01melse\u001b[39;00m step_size_settings\u001b[38;5;241m.\u001b[39mstep_size_for_warmup\n\u001b[1;32m    317\u001b[0m     hddcrp, samples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_acceptance_probability\u001b[39m\u001b[38;5;124m\"\u001b[39m][ss], samples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccepted\u001b[39m\u001b[38;5;124m\"\u001b[39m][ss] \u001b[38;5;241m=\u001b[39m Metropolis_Hastings_step_for_maze_data(hddcrp, sigma2, uniform_prior\u001b[38;5;241m=\u001b[39muniform_prior)\n",
      "File \u001b[0;32m~/gitCode/hddCRP/src/hddCRP/modelFitting.py:1037\u001b[0m, in \u001b[0;36mhddCRPModel.run_gibbs_sweep\u001b[0;34m(self, order, rng, DEBUG_MODE)\u001b[0m\n\u001b[1;32m   1035\u001b[0m codes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((order\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(order\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m-> 1037\u001b[0m     codes[order[ii,\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gibbs_sample_single_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m[\u001b[49m\u001b[43mii\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m[\u001b[49m\u001b[43mii\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEBUG_MODE\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEBUG_MODE\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (codes, order)\n",
      "File \u001b[0;32m~/gitCode/hddCRP/src/hddCRP/modelFitting.py:1190\u001b[0m, in \u001b[0;36mhddCRPModel._gibbs_sample_single_node\u001b[0;34m(self, node, layer, rng, DEBUG_MODE)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_CB_num_labeled_in_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_C_num_labeled_in_table\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_CB_num_labeled_upstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_C_num_labeled_upstream\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m-> 1190\u001b[0m can_connect_to, post, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post_for_single_nodes_connections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m   1191\u001b[0m node_to \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mchoice(can_connect_to, p \u001b[38;5;241m=\u001b[39m post\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(post))\n\u001b[1;32m   1193\u001b[0m connection_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_connection(node, node_to, layer)\n",
      "File \u001b[0;32m~/gitCode/hddCRP/src/hddCRP/modelFitting.py:1071\u001b[0m, in \u001b[0;36mhddCRPModel._post_for_single_nodes_connections\u001b[0;34m(self, node, layer, print_msgs)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m( carrying_label):\n\u001b[1;32m   1070\u001b[0m     can_connect_to \u001b[38;5;241m=\u001b[39m can_connect_to[np\u001b[38;5;241m.\u001b[39misin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_C_y[can_connect_to,layer], [hddCRPModel\u001b[38;5;241m.\u001b[39mUNKNOWN_OBSERVATION, Y_type])]; \u001b[38;5;66;03m# possible observation\u001b[39;00m\n\u001b[0;32m-> 1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(layer \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C_y\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mhddCRPModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUNKNOWN_OBSERVATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m carrying_label): \u001b[38;5;66;03m# connection to upper layers must also have correct label\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m     can_connect_to \u001b[38;5;241m=\u001b[39m can_connect_to[can_connect_to \u001b[38;5;241m!=\u001b[39m node];\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m can_connect_to\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode has no possible connections\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36misin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/numpy/lib/arraysetops.py:890\u001b[0m, in \u001b[0;36misin\u001b[0;34m(element, test_elements, assume_unique, invert, kind)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;124;03mCalculates ``element in test_elements``, broadcasting over `element` only.\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;124;03mReturns a boolean array of the same shape as `element` that is True\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m       [ True, False]])\u001b[39;00m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    889\u001b[0m element \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(element)\n\u001b[0;32m--> 890\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43min1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_elements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massume_unique\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massume_unique\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[43minvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(element\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36min1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/numpy/lib/arraysetops.py:659\u001b[0m, in \u001b[0;36min1d\u001b[0;34m(ar1, ar2, assume_unique, invert, kind)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ar1\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    658\u001b[0m     ar1_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(ar1)\n\u001b[0;32m--> 659\u001b[0m     ar1_max \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;66;03m# After masking, the range of ar1 is guaranteed to be\u001b[39;00m\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;66;03m# within the range of ar2:\u001b[39;00m\n\u001b[1;32m    663\u001b[0m     ar1_upper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mint\u001b[39m(ar1_max), \u001b[38;5;28mint\u001b[39m(ar2_max))\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2820\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2703\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[1;32m   2704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mamax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[1;32m   2705\u001b[0m          where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n\u001b[1;32m   2706\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2707\u001b[0m \u001b[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2708\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2818\u001b[0m \u001b[38;5;124;03m    5\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/JaiYuLab/lib/python3.10/site-packages/numpy/core/fromnumeric.py:69\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapreduction\u001b[39m(obj, ufunc, method, axis, dtype, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     70\u001b[0m     passkwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     71\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue}\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mu\u001b[38;5;241m.\u001b[39mndarray:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for run_idx in range(num_runs):\n",
    "    for N_blocks_per_type in range(2,max_blocks_per_type+1):\n",
    "        filename = \"{results_directory}/Sim_{sim_num}_size_{N_blocks_per_type}_run_{run_idx}.pkl\".format(results_directory=results_directory, sim_num=simulation_id, N_blocks_per_type=N_blocks_per_type, run_idx=run_idx)\n",
    "        if(not os.path.isfile(filename) or overwrite_existing_results):\n",
    "            rng_seed_sim = N_blocks_per_type + 100 + 10000*run_idx;\n",
    "            rng_seed_fit = N_blocks_per_type + 200 + 10000*run_idx;\n",
    "            rng_sim = np.random.Generator(np.random.MT19937(rng_seed_sim))\n",
    "            rng_fit = np.random.Generator(np.random.MT19937(rng_seed_fit))\n",
    "\n",
    "            session_lengths = [session_length] * (2 * N_blocks_per_type)\n",
    "            session_labels = (['A'] * N_blocks_per_type) + (['B'] * N_blocks_per_type) # which maze\n",
    "\n",
    "            seqs, connection_data = hddCRP.simulations.simulate_sequential_hddCRP(session_lengths, session_labels, action_labels, depth, rng_sim, alphas, between_session_time_constants, within_session_time_constant)\n",
    "\n",
    "\n",
    "            simulation_info = {\"rng_seed_simulation\" : rng_seed_sim, \"rng_seed_fitting\" : rng_seed_fit, \"rng_type\" : \"MT19937\",\n",
    "                            \"session_lengths\" : session_lengths, \"session_labels\" : session_labels, \"action_labels\" : action_labels,\n",
    "                            \"seqs\" : seqs, \"connection_data\" : connection_data}\n",
    "\n",
    "            model = hddCRP.simulations.create_hddCRPModel_from_simulated_sequential_hddCRP(seqs, connection_data, rng=rng_fit, use_real_connections=initialize_fit_with_real_connections)\n",
    "            \n",
    "            tau_names = [str(xx) for xx in model.weight_param_labels]\n",
    "            alphas_names = [\"alpha_concentration_no_context\", \"alpha_concentration_one_back_context\", \"alpha_concentration_two_back_context\"]\n",
    "            model, samples, step_size_settings = hddCRP.behaviorDataHandlers.sample_model_for_maze_data(model, num_samples=num_samples, num_warmup_samples=num_warmup_samples)\n",
    "\n",
    "            MCMC_info = {\"initialized_with_true_connections\" : initialize_fit_with_real_connections,\n",
    "                        \"step_size_settings\" : step_size_settings.to_dict(),\n",
    "                        \"num_warmup_samples\" : num_warmup_samples,\n",
    "                        \"num_samples\" : num_samples}\n",
    "            samples[\"tau_parameter_names\"] = tau_names\n",
    "            samples[\"alphas_names\"] = alphas_names\n",
    "            \n",
    "            # save results to filename\n",
    "            with open(filename, \"wb\") as results_file:\n",
    "                results_data = {\"true_parameters\" : true_parameters,\n",
    "                                \"simulation_info\" : simulation_info,\n",
    "                                \"MCMC_info\" : MCMC_info,\n",
    "                                \"samples\" : samples}\n",
    "                pickle.dump(results_data, results_file)\n",
    "            # \n",
    "            #   true_parameters\n",
    "            #   simulation_info\n",
    "            #   MCMC_info\n",
    "            #   samples\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_data = np.zeros((num_samples, num_runs*len(true_parameters)*(max_blocks_per_type-1)))\n",
    "empty_data.fill(np.nan)\n",
    "parameters = pd.DataFrame(empty_data,\n",
    "                  columns=pd.MultiIndex.from_product([true_parameters.keys(), range(2,max_blocks_per_type+1), range(num_runs)], names=[\"parameter\", \"sessions per maze\", \"run\"]))\n",
    "parameters.index.name='sample'\n",
    "\n",
    "# plot results: MCMC credible intervals for each parameter as a function of N_blocks_per_type\n",
    "print(\"Metropolis-Hastings acceptance rate and step size:\")\n",
    "for run_idx in range(num_runs):\n",
    "    for N_blocks_per_type in range(2,max_blocks_per_type+1):\n",
    "        filename = \"{results_directory}/Sim_{sim_num}_size_{N_blocks_per_type}_run_{run_idx}.pkl\".format(results_directory=results_directory, sim_num=simulation_id, N_blocks_per_type=N_blocks_per_type, run_idx=run_idx)\n",
    "        if(not os.path.isfile(filename)):\n",
    "            raise RuntimeError(\"Results file not found: \" + filename)\n",
    "            # throw error\n",
    "        \n",
    "        # load file\n",
    "        with open(filename, \"rb\") as results_file:\n",
    "            results = pickle.load(results_file)\n",
    "\n",
    "            '''\n",
    "            Make sure all the files loaded are correct\n",
    "            '''\n",
    "\n",
    "            # check for correct results fields\n",
    "            expected_fields = [\"true_parameters\", \"simulation_info\", \"MCMC_info\", \"samples\"]\n",
    "            if(not isinstance(results, dict) or not np.all(np.isin(expected_fields, list(results.keys())))):\n",
    "                raise ValueError(\"File \" + filename + \" does not contain expected results fields\")\n",
    "            \n",
    "            session_lengths = [session_length] * (2 * N_blocks_per_type)\n",
    "            session_labels = (['A'] * N_blocks_per_type) + (['B'] * N_blocks_per_type) # which maze\n",
    "            if(results[\"simulation_info\"][\"session_lengths\"] != session_lengths):\n",
    "                raise ValueError(\"File \" + filename + \" does not contain expected session lengths\")\n",
    "            if(results[\"simulation_info\"][\"session_labels\"] != session_labels):\n",
    "                raise ValueError(\"File \" + filename + \" does not contain expected session labels\")\n",
    "            if(results[\"simulation_info\"][\"action_labels\"] != action_labels):\n",
    "                raise ValueError(\"File \" + filename + \" does not contain expected action labels\")\n",
    "\n",
    "\n",
    "            # check if samples matches (if greater than expected, raise a warning; it less, raise an error)\n",
    "            expected_fields_samples = [\"log_taus\", \"alphas\", \"accepted\", \"num_warmup_samples\", \"tau_parameter_names\", \"alphas_names\"]\n",
    "            if(not isinstance(results[\"samples\"], dict) or not np.all(np.isin(expected_fields_samples, list(results[\"samples\"].keys())))):\n",
    "                raise ValueError(\"File \" + filename + \" does not contain expected results['samples'] fields\")\n",
    "            \n",
    "            num_samples_found = min(results[\"samples\"][\"log_taus\"].shape[0], results[\"samples\"][\"alphas\"].shape[0]) - results[\"samples\"][\"num_warmup_samples\"]\n",
    "            if(num_samples_found < num_samples):\n",
    "                raise ValueError(\"File \" + filename + \" does not contain expected number of samples in results['samples']. Found \" + str(num_samples_found) + \". Expected \" + str(num_samples) + \".\")\n",
    "\n",
    "            # check if true params match, if not, raise error\n",
    "            if(not np.all(np.isin(list(true_parameters.keys()), results[\"samples\"][\"tau_parameter_names\"] + results[\"samples\"][\"alphas_names\"]))):\n",
    "                raise ValueError(\"File \" + filename + \" does not contain expected parameters in results['samples']\")\n",
    "            if(not np.all(np.isin(list(true_parameters.keys()), list(results[\"true_parameters\"].keys()))) or not np.all(np.isin(list(results[\"true_parameters\"].keys()), list(true_parameters.keys())))):\n",
    "                raise ValueError(\"File \" + filename + \" does not contain expected parameters in results['true_parameters']\")\n",
    "            \n",
    "            for p_name in true_parameters.keys():\n",
    "                if(true_parameters[p_name] != results[\"true_parameters\"][p_name]):\n",
    "                    raise ValueError(\"File \" + filename + \" does not contain expected parameter value results['true_parameters'][\" + p_name + \"]\")\n",
    "\n",
    "            # load samples from each parameter into dataframe (multi-index: name of param and run number)\n",
    "            s_index = range(results[\"samples\"][\"num_warmup_samples\"], results[\"samples\"][\"num_warmup_samples\"] + num_samples)\n",
    "            for ii, p_name in enumerate(results[\"samples\"][\"tau_parameter_names\"] ):\n",
    "                \n",
    "                parameters.loc[:,(p_name,N_blocks_per_type,run_idx)] = np.exp(results[\"samples\"][\"log_taus\"][s_index,ii])\n",
    "            for ii, p_name in enumerate(results[\"samples\"][\"alphas_names\"] ):\n",
    "                parameters.loc[:,(p_name,N_blocks_per_type,run_idx)] = results[\"samples\"][\"alphas\"][s_index,ii]\n",
    "\n",
    "            print(\"Run \" + str(run_idx) + \", num blocks \" + str(N_blocks_per_type) + \": rate = \" + str(np.mean(results[\"samples\"][\"accepted\"][s_index])) + \", step size = \" + str(np.sqrt(results[\"MCMC_info\"][\"step_size_settings\"][\"step_size_fixed\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_s = parameters.stack([1,2]).reset_index()    \n",
    "n_cols = 2\n",
    "n_rows = int(np.ceil(len(true_parameters)/float(n_cols)))\n",
    "plt.figure(figsize=(n_cols*8,n_rows*4))\n",
    "\n",
    "print(len(true_parameters))\n",
    "for ii, p_name in enumerate(true_parameters.keys()):\n",
    "    plt.subplot(n_rows, n_cols, ii+1)\n",
    "    # for each parameter in the data frame, make a plot of 95% CI and mean over time vs. true params\n",
    "    pp = sns.lineplot(x=\"sessions per maze\", y=p_name,\n",
    "                hue=\"run\", errorbar=(\"pi\",95),\n",
    "                data=parameters_s)\n",
    "    plt.plot([2,max_blocks_per_type], [true_parameters[p_name], true_parameters[p_name]], \"k:\")\n",
    "    pp.set_xticks(range(2,max_blocks_per_type+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(parameters[\"within_session_time_constant\"][2][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa7646fadbe57c277d76ff36de8f181b6360ae43924dda8e36f9c735fd43eb1d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit ('JaiYuLab': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
