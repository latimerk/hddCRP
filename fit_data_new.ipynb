{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import hddCRP.dataLoader as dl\n",
    "import hddCRP.newContextModel as crp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diverse_TH', 'diverse_HT', 'uniform_H', 'uniform_T', 'diverse', 'uniform']\n"
     ]
    }
   ],
   "source": [
    "print(dl.grp_names_all)\n",
    "\n",
    "results_directory = \"Results/populationNew/\"\n",
    "if(not os.path.exists(results_directory)):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "OVERWRITE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting group 0: diverse_TH\n",
      "Building...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building: found in cache, done.Messages from stanc:\n",
      "Warning: The parameter timeconstant has no priors. This means either no prior\n",
      "    is provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Warning: The parameter subject_similarity has no priors. This means either no\n",
      "    prior is provided, or the prior(s) depend on data variables. In the later\n",
      "    case, this may be a false positive.\n",
      "Warning: The parameter context_weight_depth_2 has no priors. This means\n",
      "    either no prior is provided, or the prior(s) depend on data variables. In\n",
      "    the later case, this may be a false positive.\n",
      "Warning: The parameter context_weight_depth_1 has no priors. This means\n",
      "    either no prior is provided, or the prior(s) depend on data variables. In\n",
      "    the later case, this may be a false positive.\n",
      "Warning: The parameter alpha has no priors. This means either no prior is\n",
      "    provided, or the prior(s) depend on data variables. In the later case,\n",
      "    this may be a false positive.\n",
      "Sampling:   0%\n",
      "Sampling:   0% (1/8000)\n",
      "Sampling:   0% (2/8000)\n",
      "Sampling:   0% (3/8000)\n",
      "Sampling:   0% (4/8000)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fit_file = f\"{results_directory}/fit\"\n",
    "fit_summary_file = f\"{results_directory}/fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, group in enumerate(dl.grp_names_all):\n",
    "    if( (\"group\" in data_fit_metrics) and data_fit_metrics.query(\"group == @group\").size > 0):\n",
    "        print(f\"found group {ii}: {group}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"fitting group {ii}: {group}\")\n",
    "    rs = 1200 + ii;\n",
    "    model = crp.create_pop_model(group)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"group\"] = group\n",
    "    fit_df[\"subject\"] = group\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"group\"] = group\n",
    "    summary_df[\"subject\"] = group\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_file = f\"{results_directory}/ts_fit\"\n",
    "fit_summary_file = f\"{results_directory}/ts_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, group in enumerate(dl.grp_names_all):\n",
    "    if( (\"group\" in data_fit_metrics) and data_fit_metrics.query(\"group == @group\").size > 0):\n",
    "        print(f\"found group {ii}: {group}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"fitting group {ii}: {group}\")\n",
    "    rs = 1300 + ii;\n",
    "    model = crp.create_pop_model(group, fold_turns=True)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"group\"] = group\n",
    "    fit_df[\"subject\"] = group\n",
    "    fit_df[\"context_weight_depth_2.3\"] = 0\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"group\"] = group\n",
    "    summary_df[\"subject\"] = group\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_file = f\"{results_directory}/indiv_fit\"\n",
    "fit_summary_file = f\"{results_directory}/indiv_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, subject in enumerate(dl.get_subjects()):\n",
    "    if( (\"subject\" in data_fit_metrics) and data_fit_metrics.query(\"subject == @subject\").size > 0):\n",
    "        print(f\"found subject {ii}: {subject}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"fitting subject {ii}: {subject}\")\n",
    "    rs = 1400 + ii;\n",
    "    model = crp.create_indiv_model(subject)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"subject\"] = subject\n",
    "    fit_df[\"group\"] = subject\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"subject\"] = subject\n",
    "    summary_df[\"group\"] = subject\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_file = f\"{results_directory}/indiv_ts_fit\"\n",
    "fit_summary_file = f\"{results_directory}/indiv_ts_fit_summary\"\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file  += f\".pkl\"\n",
    "\n",
    "if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "else:\n",
    "    data_fits = pd.read_pickle(fit_file)\n",
    "    data_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "\n",
    "for ii, subject in enumerate(dl.get_subjects()):\n",
    "    if( (\"subject\" in data_fit_metrics) and data_fit_metrics.query(\"subject == @subject\").size > 0):\n",
    "        print(f\"found subject {ii}: {subject}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"fitting subject {ii}: {subject}\")\n",
    "    rs = 1500 + ii;\n",
    "    model = crp.create_indiv_model(subject, fold_turns=True)\n",
    "    model.build(random_seed = rs)\n",
    "    model.fit_model()\n",
    "    fit_df = model.fit.to_frame()\n",
    "    fit_df[\"subject\"] = subject\n",
    "    fit_df[\"group\"] = subject\n",
    "    fit_df[\"context_weight_depth_2.3\"] = 0\n",
    "    summary_df = model.fit_summary()\n",
    "    summary_df[\"subject\"] = subject\n",
    "    summary_df[\"group\"] = subject\n",
    "\n",
    "    data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "    data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaiYuLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
