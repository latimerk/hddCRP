{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from hddCRP.modelBuilder import cdCRP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from statannotations.Annotator import Annotator\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import itertools\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects = ['diverse', 'uniform']\n"
     ]
    }
   ],
   "source": [
    "overwrite_existing_results = False\n",
    "results_directory = \"Results/population/\"\n",
    "\n",
    "if(not os.path.exists(results_directory)):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "data_filename = 'data/Data_turns_all_by_session.pkl';\n",
    "with open(data_filename, 'rb') as data_file:\n",
    "    data = pickle.load(data_file)\n",
    "\n",
    "subjects = [\"uniform\", \"diverse\"]\n",
    "subjects.sort()\n",
    "print(\"subjects = \" + str(subjects))\n",
    "\n",
    "context_depth = 2;\n",
    "nback_depth   = 1;\n",
    "session_numbers = None#[1]; # index by 1\n",
    "number_of_trials    = 100;\n",
    "\n",
    "action_labels = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit file found\n"
     ]
    }
   ],
   "source": [
    "if(session_numbers is None):\n",
    "    fit_file = f\"{results_directory}/fits_trials_{number_of_trials}\"\n",
    "    fit_summary_file = f\"{results_directory}/fit_summary_trials_{number_of_trials}\"\n",
    "    seed_offset = number_of_trials\n",
    "else:\n",
    "    start_session = np.min(session_numbers)\n",
    "    end_session = np.max(session_numbers)\n",
    "    fit_file = f\"{results_directory}/fits_session_{start_session}\"\n",
    "    fit_summary_file = f\"{results_directory}/fit_summary_session_{start_session}\"\n",
    "    if(end_session != start_session):\n",
    "        fit_file += f\"_to_{start_session}\"\n",
    "        fit_summary_file  += f\"_to_{start_session}\"\n",
    "    seed_offset = start_session\n",
    "\n",
    "if(nback_depth != 1 or context_depth != 2):\n",
    "    fit_file += f\"_cd{context_depth}_nb{nback_depth}\"\n",
    "    fit_summary_file  += f\"_cd{context_depth}_nb{nback_depth}\"\n",
    "\n",
    "fit_file += f\".pkl\"\n",
    "fit_summary_file += f\".pkl\"\n",
    "if(not os.path.isfile(fit_file) or overwrite_existing_results):\n",
    "    data_fits = pd.DataFrame()\n",
    "    data_fit_metrics = pd.DataFrame()\n",
    "    for subject_index, subject in enumerate(subjects):\n",
    "        print(f\"subject {subject} \")\n",
    "\n",
    "        sequences = []\n",
    "        session_types = []\n",
    "        subject_labels = []\n",
    "        for subject_p in data[\"group_definition\"][subject]:\n",
    "            sequences_0 = data[\"data\"][subject_p][\"data\"]; # turns in each session\n",
    "            session_types_0 = data[\"data\"][subject_p][\"task\"] # which maze\n",
    "\n",
    "            if(session_numbers is None):\n",
    "                ii = list(np.where(np.array(session_types_0)=='C')[0])\n",
    "                seqs_c = [sequences_0[xx] for xx in ii]\n",
    "                seqs_c = list(itertools.chain.from_iterable(seqs_c))\n",
    "                sequences += [seqs_c[:number_of_trials]]\n",
    "                session_types += ['C']\n",
    "                subject_labels += [subject_p]\n",
    "            else:\n",
    "                ii = list(np.where(np.array(session_types_0)=='C')[0][np.array(session_numbers)-1])\n",
    "                sequences     += [sequences_0[xx] for xx in ii]\n",
    "                session_types += [session_types_0[xx] for xx in ii]\n",
    "                subject_labels += [subject_p] * len(ii)\n",
    "\n",
    "        stan_seed = (subject_index+1) * 1000 + seed_offset\n",
    "\n",
    "        model = cdCRP(sequences, session_labels=session_types, subject_labels=subject_labels, possible_observations=action_labels);\n",
    "        model.same_nback_depth = nback_depth\n",
    "        model.context_depth = context_depth\n",
    "\n",
    "        model.build(random_seed=stan_seed);\n",
    "        model.fit_model()\n",
    "\n",
    "        map_fit = model.get_map()\n",
    "        fit_df  = model.fit.to_frame()\n",
    "\n",
    "        fit_df[\"subject\"] = subject\n",
    "        summary_df = model.fit_summary()\n",
    "        summary_df[\"subject\"] = subject\n",
    "        summary_df[\"MAP\"] = pd.Series(map_fit)\n",
    "        if(session_numbers is None):\n",
    "            summary_df[\"number_of_trials\"] = number_of_trials\n",
    "            summary_df[\"start_session_C\"]  = pd.NA\n",
    "            summary_df[\"end_session_C\"]    = pd.NA\n",
    "            fit_df[\"number_of_trials\"] = number_of_trials\n",
    "            fit_df[\"start_session_C\"]  = pd.NA\n",
    "            fit_df[\"end_session_C\"]    = pd.NA\n",
    "        else:\n",
    "            summary_df[\"number_of_trials\"] = pd.NA\n",
    "            summary_df[\"start_session_C\"]  = start_session\n",
    "            summary_df[\"end_session_C\"]    = end_session\n",
    "            fit_df[\"number_of_trials\"] = pd.NA\n",
    "            fit_df[\"start_session_C\"]  = start_session\n",
    "            fit_df[\"end_session_C\"]    = end_session\n",
    "\n",
    "        data_fit_metrics = pd.concat([data_fit_metrics,summary_df], copy=False)\n",
    "        data_fits = pd.concat([data_fits,fit_df], copy=False)\n",
    "\n",
    "    data_fits.to_pickle(fit_file)\n",
    "    data_fit_metrics.to_pickle(fit_summary_file)\n",
    "else:\n",
    "    print(\"fit file found\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>parameters</th>\n",
       "      <th>lp__</th>\n",
       "      <th>accept_stat__</th>\n",
       "      <th>stepsize__</th>\n",
       "      <th>treedepth__</th>\n",
       "      <th>n_leapfrog__</th>\n",
       "      <th>divergent__</th>\n",
       "      <th>energy__</th>\n",
       "      <th>alpha</th>\n",
       "      <th>timeconstant_within_session_C</th>\n",
       "      <th>repeat_bias_1_back</th>\n",
       "      <th>context_similarity_depth_1</th>\n",
       "      <th>context_similarity_depth_2</th>\n",
       "      <th>subject</th>\n",
       "      <th>number_of_trials</th>\n",
       "      <th>start_session_C</th>\n",
       "      <th>end_session_C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>draws</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-963.691587</td>\n",
       "      <td>0.900097</td>\n",
       "      <td>0.486370</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>969.192488</td>\n",
       "      <td>5.074392</td>\n",
       "      <td>28.059196</td>\n",
       "      <td>0.976909</td>\n",
       "      <td>0.905401</td>\n",
       "      <td>0.078246</td>\n",
       "      <td>diverse</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-959.389314</td>\n",
       "      <td>0.861784</td>\n",
       "      <td>0.547604</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>961.265363</td>\n",
       "      <td>2.376460</td>\n",
       "      <td>44.751409</td>\n",
       "      <td>0.662627</td>\n",
       "      <td>0.853212</td>\n",
       "      <td>0.482617</td>\n",
       "      <td>diverse</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-959.979959</td>\n",
       "      <td>0.948568</td>\n",
       "      <td>0.565220</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>960.478307</td>\n",
       "      <td>3.744173</td>\n",
       "      <td>27.560810</td>\n",
       "      <td>0.509202</td>\n",
       "      <td>0.793253</td>\n",
       "      <td>0.355549</td>\n",
       "      <td>diverse</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-965.536217</td>\n",
       "      <td>0.831479</td>\n",
       "      <td>0.416612</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>966.321926</td>\n",
       "      <td>6.026395</td>\n",
       "      <td>72.076291</td>\n",
       "      <td>0.601749</td>\n",
       "      <td>0.295470</td>\n",
       "      <td>0.774897</td>\n",
       "      <td>diverse</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-961.581044</td>\n",
       "      <td>0.966101</td>\n",
       "      <td>0.486370</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>965.400025</td>\n",
       "      <td>3.563361</td>\n",
       "      <td>31.063167</td>\n",
       "      <td>0.557241</td>\n",
       "      <td>0.961190</td>\n",
       "      <td>0.431229</td>\n",
       "      <td>diverse</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>-1080.791075</td>\n",
       "      <td>0.816319</td>\n",
       "      <td>0.495197</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1081.699834</td>\n",
       "      <td>7.372000</td>\n",
       "      <td>28.955316</td>\n",
       "      <td>0.985973</td>\n",
       "      <td>0.471936</td>\n",
       "      <td>0.872592</td>\n",
       "      <td>uniform</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>-1078.931526</td>\n",
       "      <td>0.920430</td>\n",
       "      <td>0.594087</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1081.105994</td>\n",
       "      <td>3.736188</td>\n",
       "      <td>35.375710</td>\n",
       "      <td>0.811518</td>\n",
       "      <td>0.341901</td>\n",
       "      <td>0.837610</td>\n",
       "      <td>uniform</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>-1079.107245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.479113</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1083.110699</td>\n",
       "      <td>4.551114</td>\n",
       "      <td>62.874407</td>\n",
       "      <td>1.185255</td>\n",
       "      <td>0.356120</td>\n",
       "      <td>0.797080</td>\n",
       "      <td>uniform</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>-1078.117119</td>\n",
       "      <td>0.934105</td>\n",
       "      <td>0.576204</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1079.490373</td>\n",
       "      <td>4.719203</td>\n",
       "      <td>26.736792</td>\n",
       "      <td>1.090076</td>\n",
       "      <td>0.681612</td>\n",
       "      <td>0.831471</td>\n",
       "      <td>uniform</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>-1080.245451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.495197</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1082.235342</td>\n",
       "      <td>3.940339</td>\n",
       "      <td>98.577727</td>\n",
       "      <td>1.021107</td>\n",
       "      <td>0.201124</td>\n",
       "      <td>0.900994</td>\n",
       "      <td>uniform</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "parameters         lp__  accept_stat__  stepsize__  treedepth__  n_leapfrog__  \\\n",
       "draws                                                                           \n",
       "0           -963.691587       0.900097    0.486370          3.0          15.0   \n",
       "1           -959.389314       0.861784    0.547604          3.0           7.0   \n",
       "2           -959.979959       0.948568    0.565220          2.0           3.0   \n",
       "3           -965.536217       0.831479    0.416612          3.0           7.0   \n",
       "4           -961.581044       0.966101    0.486370          3.0           7.0   \n",
       "...                 ...            ...         ...          ...           ...   \n",
       "3995       -1080.791075       0.816319    0.495197          2.0           7.0   \n",
       "3996       -1078.931526       0.920430    0.594087          3.0           7.0   \n",
       "3997       -1079.107245       1.000000    0.479113          3.0           7.0   \n",
       "3998       -1078.117119       0.934105    0.576204          3.0           7.0   \n",
       "3999       -1080.245451       1.000000    0.495197          3.0           7.0   \n",
       "\n",
       "parameters  divergent__     energy__     alpha  timeconstant_within_session_C  \\\n",
       "draws                                                                           \n",
       "0                   0.0   969.192488  5.074392                      28.059196   \n",
       "1                   0.0   961.265363  2.376460                      44.751409   \n",
       "2                   0.0   960.478307  3.744173                      27.560810   \n",
       "3                   0.0   966.321926  6.026395                      72.076291   \n",
       "4                   0.0   965.400025  3.563361                      31.063167   \n",
       "...                 ...          ...       ...                            ...   \n",
       "3995                0.0  1081.699834  7.372000                      28.955316   \n",
       "3996                0.0  1081.105994  3.736188                      35.375710   \n",
       "3997                0.0  1083.110699  4.551114                      62.874407   \n",
       "3998                0.0  1079.490373  4.719203                      26.736792   \n",
       "3999                0.0  1082.235342  3.940339                      98.577727   \n",
       "\n",
       "parameters  repeat_bias_1_back  context_similarity_depth_1  \\\n",
       "draws                                                        \n",
       "0                     0.976909                    0.905401   \n",
       "1                     0.662627                    0.853212   \n",
       "2                     0.509202                    0.793253   \n",
       "3                     0.601749                    0.295470   \n",
       "4                     0.557241                    0.961190   \n",
       "...                        ...                         ...   \n",
       "3995                  0.985973                    0.471936   \n",
       "3996                  0.811518                    0.341901   \n",
       "3997                  1.185255                    0.356120   \n",
       "3998                  1.090076                    0.681612   \n",
       "3999                  1.021107                    0.201124   \n",
       "\n",
       "parameters  context_similarity_depth_2  subject  number_of_trials  \\\n",
       "draws                                                               \n",
       "0                             0.078246  diverse               100   \n",
       "1                             0.482617  diverse               100   \n",
       "2                             0.355549  diverse               100   \n",
       "3                             0.774897  diverse               100   \n",
       "4                             0.431229  diverse               100   \n",
       "...                                ...      ...               ...   \n",
       "3995                          0.872592  uniform               100   \n",
       "3996                          0.837610  uniform               100   \n",
       "3997                          0.797080  uniform               100   \n",
       "3998                          0.831471  uniform               100   \n",
       "3999                          0.900994  uniform               100   \n",
       "\n",
       "parameters start_session_C end_session_C  \n",
       "draws                                     \n",
       "0                      NaN           NaN  \n",
       "1                      NaN           NaN  \n",
       "2                      NaN           NaN  \n",
       "3                      NaN           NaN  \n",
       "4                      NaN           NaN  \n",
       "...                    ...           ...  \n",
       "3995                   NaN           NaN  \n",
       "3996                   NaN           NaN  \n",
       "3997                   NaN           NaN  \n",
       "3998                   NaN           NaN  \n",
       "3999                   NaN           NaN  \n",
       "\n",
       "[8000 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_name_map = {\"alpha\" : \"concentration\", \n",
    "                      \"context_similarity_depth_1\" : \"context weight level 1\",\n",
    "                      \"context_similarity_depth_2\" : \"context weight level 2\", \n",
    "                      \"repeat_bias_1_back\" : \"repeat bias\",\n",
    "                      \"timeconstant_within_session_A\" : \"time constant\",\n",
    "                      \"timeconstant_within_session_C\" : \"time constant\"}\n",
    "\n",
    " \n",
    "summary_df = pd.read_pickle(fit_summary_file)\n",
    "summary_df.index.name = \"parameter\"\n",
    "summary_df = summary_df.reset_index()\n",
    "summary_df[\"parameter\"] = summary_df[\"parameter\"].map(parameter_name_map)\n",
    "data_fits  = pd.read_pickle(fit_file)\n",
    "data_fits.rename(columns=parameter_name_map, inplace=True)\n",
    "\n",
    "params = list(summary_df[\"parameter\"].unique());\n",
    "\n",
    "data_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "draws\n",
       "0         [5.074392192948843, 0.9054014629780311]\n",
       "1        [2.3764598307168714, 0.8532117692493647]\n",
       "2         [3.7441734403736797, 0.793252983119751]\n",
       "3            [6.026394702997351, 0.2954696788896]\n",
       "4         [3.563360938777622, 0.9611896338996332]\n",
       "                          ...                    \n",
       "3995       [7.37199955239934, 0.4719363563965383]\n",
       "3996    [3.7361875438202627, 0.34190079536686196]\n",
       "3997      [4.551113924387478, 0.3561201789406736]\n",
       "3998      [4.719203478628664, 0.6816121090404115]\n",
       "3999      [3.940338686588198, 0.2011235086309134]\n",
       "Length: 8000, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_seed = 10;\n",
    "sim_rng = np.random.Generator(np.random.MT19937(pval_seed))\n",
    "\n",
    "pval = np.zeros((len(params)))\n",
    "pval2 = np.zeros((len(params)))\n",
    "for ii, param in enumerate(params):\n",
    "    #fit.hist(params[ii], by=\"subject\", ax=ax);\n",
    "    cat_type = CategoricalDtype(categories=[\"uniform\", \"diverse\"], ordered=False)\n",
    "    df_c = data_fits[[\"subject\", param]]\n",
    "    df_c = df_c.assign(subject_c= df_c[\"subject\"].astype(cat_type))\n",
    "    df_c = df_c.assign(subject_c2= df_c[\"subject\"].astype(cat_type))\n",
    "    df_c['subject_c'].replace(['uniform', 'diverse'],\n",
    "                            [0, 1], inplace=True)\n",
    "    df_c['subject_c2'].replace(['uniform', 'diverse'],\n",
    "                            [1, 0], inplace=True)\n",
    "    pval[ii]  = roc_auc_score(df_c['subject_c' ].to_numpy(), df_c[param].to_numpy())\n",
    "    pval2[ii] = roc_auc_score(df_c['subject_c2'].to_numpy(), df_c[param].to_numpy())\n",
    "\n",
    "    print(f\"{param}: p(diverse > uniform) = {pval[ii]} (opp = {pval2[ii]})\")\n",
    "\n",
    "\n",
    "df_c2 = data_fits.melt(value_vars=params, id_vars=[\"subject\"])\n",
    "\n",
    "\n",
    "sns.displot(\n",
    "    df_c2, x=\"value\", col=\"parameters\", hue=\"subject\", palette=\"colorblind\",\n",
    "    height=3, facet_kws={\"margin_titles\": True, \"sharex\" :False},common_bins=False\n",
    ")\n",
    "\n",
    "params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.pairplot(data_fits, hue=\"subject\", vars=params,\n",
    "    plot_kws=dict(s=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_fits[[\"repeat bias\", \"context weight level 1\"]]#[params]\n",
    "y = data_fits['subject']\n",
    "\n",
    "#define cross-validation method to use\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "#build multiple linear regression model\n",
    "model = SVC(kernel='linear', C=1, random_state=192)\n",
    "\n",
    "#use LOOCV to evaluate model\n",
    "scores = cross_val_score(model, X, y,\n",
    "                         cv=cv, n_jobs=-1)\n",
    "\n",
    "#view mean absolute error\n",
    "np.mean(np.absolute(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaiYuLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
