{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import hddCRP.behaviorDataHandlers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "context_length = 2;\n",
    "num_runs = 1;\n",
    "runs = range(num_runs);\n",
    "num_warmup_samples = 5000\n",
    "num_samples        = 20000\n",
    "overwrite_existing_results = False\n",
    "\n",
    "binarize_choices = True;\n",
    "\n",
    "num_sessions = 1;\n",
    "num_sessions_str = str(num_sessions) if num_sessions > 1 else '';\n",
    "\n",
    "simple_model = False\n",
    "single_concentration = False\n",
    "sequential_distances_only = True # if false, model setup more as a \"smoother\". If true, can simulate from the model\n",
    "\n",
    "if(sequential_distances_only):\n",
    "    results_directory = \"Results/Pop\" + num_sessions_str + \"/sequentialModel/\"\n",
    "else:\n",
    "    results_directory = \"Results/Pop\" + num_sessions_str + \"/\"\n",
    "\n",
    "if(binarize_choices):\n",
    "    results_directory += \"binary/\"\n",
    "\n",
    "\n",
    "if(simple_model):\n",
    "    results_directory += \"simple/\"\n",
    "elif(single_concentration):\n",
    "    results_directory += \"singleAlpha/\"\n",
    "\n",
    "if(not os.path.exists(results_directory)):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "data_filename = 'data/Data_turns_all_by_session.pkl';\n",
    "with open(data_filename, 'rb') as data_file:\n",
    "    data = pickle.load(data_file)\n",
    "\n",
    "subjects_0 = list(data[\"data\"].keys())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cc = 1;\n",
    "prior_scales = None;#{\"alpha\" : 5/cc, \"tau_within\" : 25, \"tau_between\" : 5}\n",
    "prior_shapes = None;#{\"alpha\" : 2*cc, \"tau_within\" :  2, \"tau_between\" : 2}\n",
    "\n",
    "group_names = np.array([\"all\", \"uniform\", \"diverse\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjects = ['A1', 'B1', 'C1', 'D1', 'E1', 'F1', 'G1', 'H1', 'I1', 'J1']\n",
      "RUN 0\n",
      "Results/Pop/sequentialModel/binary//Subs_1_context_1_run_0.pkl\n",
      "subjects = ['A2', 'B2', 'C2', 'D2', 'E2', 'F2', 'G2', 'I2', 'J2']\n",
      "RUN 0\n",
      "Results/Pop/sequentialModel/binary//Subs_2_context_1_run_0.pkl\n"
     ]
    }
   ],
   "source": [
    "for subs in [1,2]:\n",
    "    # subjects = [\"A1\"] subs = 2;\n",
    "    # if(subs != 0):\n",
    "    #     subjects_id = np.array([True if xx.endswith(str(subs)) else False for xx in subjects_0])\n",
    "    #     subjects = np.array(subjects_0)\n",
    "    #     subjects = subjects[subjects_id]\n",
    "    # else:\n",
    "    #     subjects = subjects_0\n",
    "\n",
    "    if(subs == 0):\n",
    "        subjects = subjects_0;\n",
    "    else:\n",
    "        subjects = data[\"group_definition\"][group_names[subs]]\n",
    "\n",
    "    subjects.sort()\n",
    "    print(\"subjects = \" + str(subjects))\n",
    "    for run_idx in runs:\n",
    "        print(f\"RUN {run_idx}\")\n",
    "        filename = \"{results_directory}/Subs_{subs}_context_{context_length}_run_{run_idx}.pkl\".format(subs=subs, results_directory=results_directory, run_idx=run_idx, context_length=context_length)\n",
    "        print(filename)\n",
    "        if(not os.path.isfile(filename) or overwrite_existing_results):\n",
    "            # for each run, should do some randomization of initial parameters (with known seeds so we can repeat everything)\n",
    "\n",
    "            seed = subs * 1000 + run_idx;\n",
    "            rng = np.random.Generator(np.random.MT19937(seed))\n",
    "\n",
    "            models = [];\n",
    "            for subject_idx, subject in enumerate(subjects):\n",
    "                sequences = data[\"data\"][subject][\"data\"]; # turns in each session\n",
    "                session_types = data[\"data\"][subject][\"task\"] # which maze\n",
    "\n",
    "                ii = session_types.index(\"C\")\n",
    "                sequences = sequences[ii:ii+num_sessions].copy()\n",
    "                session_types = session_types[ii:ii+num_sessions]\n",
    "\n",
    "                if(binarize_choices):\n",
    "                    for seq in sequences:\n",
    "                        for ii, ss in enumerate(seq):\n",
    "                            if((data[\"turn_definition\"][ss].upper().startswith(\"L\")) or (data[\"turn_definition\"][ss].upper().startswith(\"R\"))):\n",
    "                                seq[ii] = 3\n",
    "\n",
    "                model = hddCRP.behaviorDataHandlers.create_hddCRP(sequences, session_types, rng = rng, \n",
    "                        sequential_distances_only=sequential_distances_only, depth=(context_length+1), include_timescales=(not simple_model))\n",
    "                models += [model]\n",
    "            tau_names = [str(xx) for xx in models[0].weight_param_labels]\n",
    "\n",
    "            alphas_names = [\"alpha_concentration_no_context\", \"alpha_concentration_one_back_context\", \"alpha_concentration_two_back_context\"]\n",
    "            alphas_names = alphas_names[:(context_length+1)]\n",
    "            models, samples, step_size_settings = hddCRP.behaviorDataHandlers.sample_population_model_for_maze_data(models, num_samples=num_samples, num_warmup_samples=num_warmup_samples, \n",
    "                print_every=2500, single_concentration_parameter=single_concentration,  prior_shapes=prior_shapes, prior_scales=prior_scales)\n",
    "        \n",
    "            MCMC_info = {\"step_size_settings\" : step_size_settings.to_dict(),\n",
    "                        \"num_warmup_samples\" : num_warmup_samples,\n",
    "                        \"num_samples\" : num_samples,\n",
    "                        \"seed\" : seed, \n",
    "                        \"sequential_distances_only\" : sequential_distances_only, \n",
    "                        \"binarize_choices\" : binarize_choices}\n",
    "            samples[\"tau_parameter_names\"] = tau_names\n",
    "            samples[\"alphas_names\"] = alphas_names\n",
    "            samples[\"stats\"] = [{\"subject\" : subjects[ii], \"contexts\" : models[ii]._groupings, \"observations\" : models[ii]._Y} for ii in range(len(subjects))]\n",
    "            \n",
    "            # save results to filename\n",
    "            with open(filename, \"wb\") as results_file:\n",
    "                results_data = {\"MCMC_info\" : MCMC_info,\n",
    "                                \"samples\" : samples}\n",
    "                pickle.dump(results_data, results_file)\n",
    "                print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_names = [\"alpha_concentration_no_context\", \"alpha_concentration_one_back_context\", \"alpha_concentration_two_back_context\"]\n",
    "alphas_names = alphas_names[:(context_length+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "taus = np.zeros((num_samples,min(2,num_sessions),len(runs),3))\n",
    "alphas = np.zeros((num_samples,context_length+1,len(runs),3))\n",
    "\n",
    "for run_idx in runs:\n",
    "    for subs_idx, subs in enumerate([0,1,2]):\n",
    "        filename = \"{results_directory}/Subs_{subs}_context_{context_length}_run_{run_idx}.pkl\".format(subs=subs, results_directory=results_directory, run_idx=run_idx, context_length=context_length)\n",
    "        if(os.path.exists(filename)):\n",
    "            with open(filename, \"rb\") as file:\n",
    "                results = pickle.load(file)\n",
    "\n",
    "                ss = range(results[\"MCMC_info\"][\"num_warmup_samples\"], results[\"MCMC_info\"][\"num_warmup_samples\"]+results[\"MCMC_info\"][\"num_samples\"])\n",
    "                taus[:,:,run_idx,subs_idx] = np.exp(results[\"samples\"][\"log_taus\"][ss,:])\n",
    "                alphas[:,:,run_idx,subs_idx] = results[\"samples\"][\"alphas\"][ss,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute these from predictive distributions\n",
    "# p(straight or turn|turn)\n",
    "# p(turn or straight | straight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = np.array([1,2])\n",
    "run_idx = 0;\n",
    "T = taus.shape[1]\n",
    "plt.figure(figsize=((3+T)*4,4))\n",
    "for ii in range(alphas.shape[1]):\n",
    "    plt.subplot(1,3+T,ii+1)\n",
    "    plt.hist(np.squeeze(alphas[:,ii,run_idx,rr]),30)\n",
    "    plt.xlabel(alphas_names[ii])\n",
    "for tt in range(T):\n",
    "    plt.subplot(1,3+T,4+tt)\n",
    "    plt.hist(np.squeeze(taus[:,tt,run_idx,rr]),30);\n",
    "    plt.xlabel(samples[\"tau_parameter_names\"][tt])\n",
    "plt.legend(group_names[rr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import gmean\n",
    "s1 = 1;\n",
    "s2 = 2\n",
    "\n",
    "a2 = alphas[:,:,run_idx,s2];\n",
    "a1 = alphas[:,:,run_idx,s1];\n",
    "t2 = taus[:,:,run_idx,s2];\n",
    "t1 = taus[:,:,run_idx,s1];\n",
    "\n",
    "# a1[:,0] = a1[:,0] - np.mean(a1[:,1:],axis=1)\n",
    "# a2[:,0] = a2[:,0] - np.mean(a2[:,1:],axis=1)\n",
    "\n",
    "\n",
    "# t1 = np.mean(a1,axis=1)\n",
    "# t2 = np.mean(a2,axis=1)\n",
    "# t1 = gmean(a1,axis=1)\n",
    "# t2 = gmean(a2,axis=1)\n",
    "\n",
    "NA = alphas.shape[1];\n",
    "a1c = a1.copy()\n",
    "a2c = a2.copy()\n",
    "t1c = t1.copy()\n",
    "t2c = t2.copy()\n",
    "\n",
    "a1c[:,:] = a1c[np.random.permutation(a1c.shape[0]),:]\n",
    "a2c[:,:] = a2c[np.random.permutation(a2c.shape[0]),:]\n",
    "ac = a2c > a1c;\n",
    "print(np.mean(ac,axis=0))\n",
    "\n",
    "    \n",
    "t1c[:,:] = t1c[np.random.permutation(t1c.shape[0]),:]\n",
    "t2c[:,:] = t2c[np.random.permutation(t2c.shape[0]),:]\n",
    "print(np.mean(t2c > t1c,axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"group_definition\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaiYuLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
