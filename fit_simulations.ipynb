{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from hddCRP.simulations import simulate_sessions\n",
    "from hddCRP.modelBuilder import cdCRP\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_blocks   = 20\n",
    "N_sims_per_block = 50\n",
    "simulation_range = [0,1]\n",
    "\n",
    "block_range = range(1, N_sims_per_block+1)\n",
    "run_range = range(0, N_blocks)\n",
    "\n",
    "results_directory = \"Results/Simulations/\"\n",
    "OVERWRITE = False;\n",
    "\n",
    "if(not os.path.exists(results_directory)):\n",
    "    os.makedirs(results_directory)\n",
    "\n",
    "include_repeat_bias   = True;\n",
    "context_depth = 1;\n",
    "\n",
    "if(include_repeat_bias):\n",
    "    nback_depth   = 1;\n",
    "else:\n",
    "    nback_depth   = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for simulation_id in simulation_range:\n",
    "\n",
    "    if(simulation_id == 0):\n",
    "        alpha = 5\n",
    "        different_context_weights = [0.2, 0.2];\n",
    "        within_session_timescales  = {\"A\" : 20}\n",
    "        between_session_timescales = None; #{(\"A\",\"A\") : 2}\n",
    "        repeat_bias_1_back = 0.5\n",
    "\n",
    "        session_labels  = lambda n_blocks : [\"A\"] ;\n",
    "        session_lengths = lambda n_blocks : [25 * n_blocks ];\n",
    "        num_subjects = lambda n_blocks : 1;\n",
    "        num_responses = 3\n",
    "        simulation_name = \"sim. 1\"\n",
    "    elif(simulation_id == 1):\n",
    "        alpha = 3\n",
    "        different_context_weights = [0.8, 0.8];\n",
    "        within_session_timescales  = {\"A\" : 50}\n",
    "        between_session_timescales = None; #{(\"A\",\"A\") : 2}\n",
    "        repeat_bias_1_back = 1.0\n",
    "\n",
    "        session_labels  = lambda n_blocks : [\"A\"] ;\n",
    "        session_lengths = lambda n_blocks : [25 * n_blocks ];\n",
    "        num_subjects = lambda n_blocks :  1;\n",
    "        num_responses = 3\n",
    "        simulation_name = \"sim. 2\"\n",
    "    else:\n",
    "        raise NotImplementedError(\"No sim found\")\n",
    "    \n",
    "    if(not nback_depth):\n",
    "        repeat_bias_1_back = None;\n",
    "    different_context_weights = different_context_weights[:context_depth]\n",
    "    \n",
    "    fit_file = f\"{results_directory}/simulation_{simulation_id}\"\n",
    "    fit_summary_file = f\"{results_directory}/simulation_summary_{simulation_id}\"\n",
    "    fit_file += f\"_cd{context_depth}_nb{nback_depth}\"\n",
    "    fit_summary_file  += f\"_cd{context_depth}_nb{nback_depth}\"\n",
    "    fit_file += f\".pkl\"\n",
    "    fit_summary_file  += f\".pkl\"\n",
    "\n",
    "        \n",
    "    if(((not os.path.isfile(fit_file)) or (not os.path.isfile(fit_summary_file))) or OVERWRITE):\n",
    "        simulation_fits = pd.DataFrame()\n",
    "        simulation_fit_metrics = pd.DataFrame()\n",
    "    else:\n",
    "        simulation_fits = pd.read_pickle(fit_file)\n",
    "        simulation_fit_metrics = pd.read_pickle(fit_summary_file)\n",
    "\n",
    "    for block_idx in block_range:\n",
    "        print(f\"BLOCK {block_idx}\")\n",
    "\n",
    "        \n",
    "        for run_idx in run_range:\n",
    "            if(not (\"simulation_id\" in simulation_fit_metrics) or not (\"block\" in simulation_fit_metrics) or not (\"run\" in simulation_fit_metrics) or\n",
    "                simulation_fit_metrics.query(\"simulation_id == @simulation_id and block == @block_idx and run == @run_idx\").size == 0):\n",
    "                print(f\"BLOCK {block_idx} - RUN {run_idx}\")\n",
    "                sim_seed  = (simulation_id+8) * 10000 + nback_depth * 1001 + context_depth * 1000 + run_idx*100 \n",
    "                stan_seed = (simulation_id+8) * 10000 + nback_depth * 1001 + context_depth * 1000 + run_idx*100 + block_idx\n",
    "                \n",
    "                seqs = [];\n",
    "                subject_labels = [];\n",
    "                session_labels_all = [];\n",
    "                for jj in range(num_subjects(block_idx)):\n",
    "                    sim_rng = np.random.Generator(np.random.MT19937(sim_seed + jj))\n",
    "                    seqs_c = simulate_sessions(session_lengths=session_lengths(block_idx), session_labels=session_labels(block_idx), num_responses=num_responses, \n",
    "                                            alpha=alpha,\n",
    "                                            different_context_weights=different_context_weights,\n",
    "                                            within_session_timescales=within_session_timescales, between_session_timescales=between_session_timescales,\n",
    "                                            repeat_bias_1_back=repeat_bias_1_back, rng=sim_rng)\n",
    "                    subject_labels += [jj] * len(seqs_c)\n",
    "                    session_labels_all += session_labels(block_idx)\n",
    "                    seqs += seqs_c;\n",
    "\n",
    "                model = cdCRP(seqs, subject_labels=subject_labels, session_labels=session_labels_all);\n",
    "                model.same_nback_depth = nback_depth;\n",
    "                model.context_depth = context_depth;\n",
    "                \n",
    "                model.context_depth = len(different_context_weights)\n",
    "                model.build(random_seed=stan_seed);\n",
    "                model.fit_model()\n",
    "\n",
    "                fit_df = model.fit.to_frame()\n",
    "                fit_df[\"block\"] = block_idx\n",
    "                fit_df[\"run\"]   = run_idx\n",
    "                fit_df[\"simulation_id\"]   = simulation_id\n",
    "                summary_df = model.fit_summary()\n",
    "                summary_df[\"block\"] = block_idx\n",
    "                summary_df[\"run\"]   = run_idx\n",
    "                summary_df[\"simulation_id\"]   = simulation_id\n",
    "                summary_df[\"trials\"]   = model.session_lengths.sum()\n",
    "                summary_df[\"sessions\"]   = model.num_sessions\n",
    "                summary_df[\"n_subjects\"]   = model.num_subjects\n",
    "                summary_df[\"simulation\"]   = simulation_name\n",
    "                #map_fit = model.get_map()\n",
    "                #summary_df[\"MAP\"] = pd.Series(map_fit)\n",
    "\n",
    "                true_param = {\"alpha\" : alpha,\n",
    "                \"timeconstant_within_session_A\" : within_session_timescales[\"A\"]}\n",
    "                if(nback_depth >= 1):\n",
    "                    true_param[\"repeat_bias_1_back\"] = repeat_bias_1_back\n",
    "                if(nback_depth >= 1):\n",
    "                    true_param[\"context_similarity_depth_1\"] = different_context_weights[0]\n",
    "                if(nback_depth >= 21):\n",
    "                    true_param[\"context_similarity_depth_2\"] = different_context_weights[1]\n",
    "\n",
    "                summary_df[\"true\"] = pd.Series(true_param)\n",
    "                \n",
    "\n",
    "                simulation_fit_metrics = pd.concat([simulation_fit_metrics,summary_df], copy=False)\n",
    "                simulation_fits = pd.concat([simulation_fits,fit_df], copy=False)\n",
    "\n",
    "                simulation_fits.to_pickle(fit_file)\n",
    "                simulation_fit_metrics.to_pickle(fit_summary_file)\n",
    "            else:\n",
    "                print(\"Fit files found: not overriding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_fit_metrics = pd.DataFrame()\n",
    "for simulation_id in [0,1]:\n",
    "    fit_summary_file = f\"{results_directory}/simulation_summary_{simulation_id}\"\n",
    "    fit_summary_file  += f\"_cd{context_depth}_nb{nback_depth}\"\n",
    "    fit_summary_file  += f\".pkl\"\n",
    "    simulation_fit_metrics = pd.concat([simulation_fit_metrics, pd.read_pickle(fit_summary_file)])\n",
    "simulation_fit_metrics[\"simulation\"] = simulation_fit_metrics[\"simulation\"].astype(\"category\")\n",
    "simulation_fit_metrics.reset_index(names=\"parameter\", inplace=True)\n",
    "simulation_fit_metrics[\"parameter\"] = simulation_fit_metrics[\"parameter\"].map({\"alpha\" : \"alpha\",\n",
    "                                          \"context_similarity_depth_1\" : \"C\",\n",
    "                                          \"context_similarity_depth_2\" : \"C2\",\n",
    "                                          \"repeat_bias_1_back\" : \"B\",\n",
    "                                          \"timeconstant_within_session_A\" : \"tau\"})\n",
    "\n",
    "var_to_plot = \"median\"\n",
    "palette=\"colorblind\"   \n",
    "g = sns.FacetGrid(simulation_fit_metrics, row=\"parameter\", height=1.5, aspect=10/(1.5), sharey=False);\n",
    "g.map_dataframe(sns.pointplot, x=\"trials\", y=var_to_plot, errorbar=(\"pi\",90), dodge=0.1, hue=\"simulation\", palette=palette);\n",
    "g.map_dataframe(sns.pointplot, x=\"trials\", y=\"true\",  linestyles=\"--\", markers=\"\", hue=\"simulation\", palette=palette); #\n",
    "g.add_legend()\n",
    "for ax in g.axes[:,0]:\n",
    "    ax.set_ylabel(None);\n",
    "\n",
    "g.axes[-1,0].set_ylabel('estimate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaiYuLab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
